{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model as lm, metrics, ensemble as ens\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE, RFECV, SequentialFeatureSelector\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a43f45",
   "metadata": {},
   "source": [
    "# Clinical Data updated_ Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING A FUNCTION TO UPDATE COLUMN NAMES LATER\n",
    "def lower_no_space(word): \n",
    "    \n",
    "    word = re.sub(' ', '_', word) \n",
    "    \n",
    "    word = re.sub(r'\\'', '', word) \n",
    "    \n",
    "    word = re.sub(r'\\(', '', word)\n",
    "    \n",
    "    word = re.sub(r'\\)', '', word)\n",
    "    \n",
    "    word = re.sub('\\?', '', word)\n",
    "    \n",
    "    word = re.sub('/', '_', word)\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ IN Updated CLINICAL DATA FOR LATER USE (CONVERTED TO .csv IN GOOGLE SHEETS)\n",
    "df_clin_updated = pd.read_csv(\"Homebase_new_updated.csv\", header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAMING COLUMNS\n",
    "df_clin_updated = df_clin_updated.rename(mapper = lower_no_space, axis = 1) \n",
    "df_clin_updated.rename(columns={'subject_sample_id':'sample_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK CLINICAL DATA BASICS\n",
    "df_clin_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a05600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the age at initial diagnosis from date of birth and date_of_initial_diagnosis\n",
    "df_clin_updated['date_of_birth'] = pd.to_datetime(df_clin_updated['date_of_birth'])\n",
    "df_clin_updated['date_of_initial_diagnosis'] = pd.to_datetime(df_clin_updated['date_of_initial_diagnosis'])\n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = (pd.DatetimeIndex(df_clin_updated['date_of_initial_diagnosis']).year \n",
    "                        - pd.DatetimeIndex(df_clin_updated['date_of_birth']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf3174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the abnormal in date of birth from the Stanford data, \n",
    "#Remove the age at initial diagonosis for data from Stanford & the one that has negative age \n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = np.where(df_clin_updated['data_access_group'] == 'Stanford', np.nan, df_clin_updated[\"age_at_initial_diagnosis\"])\n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = np.where(df_clin_updated[\"age_at_initial_diagnosis\"] < 0, np.nan, df_clin_updated[\"age_at_initial_diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data type: date_of_birth, n, m \n",
    "df_clin_updated = df_clin_updated.astype({'t':'object', 'b':'object'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TONS OF DATA, PULL WHAT WE WANT\n",
    "df_clin_updated_lean = df_clin_updated.drop(columns = [x for x in df_clin_updated.columns if x not in ['gender', 'race', \\\n",
    "                                       'country_of_residence', 'sample_id', 'ethnicity',\\\n",
    "                                        'age_at_initial_diagnosis',\\\n",
    "                                        'lymph_node_biopsy_performed','predominant_lesion_type_at_diagnosis',\\\n",
    "                                        'family_history_of_leukemia_lymphoma', 't', 'n', 'm', 'b',\\\n",
    "                                        'has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical',\\\n",
    "                                        'cd4+:cd8+_ratio', 'total_lymphocyte_count', 'absolute_cd4+_count_per_ul',\\\n",
    "                                        '%cd4+cd26-', '%cd4+cd7-', 'tcr_clonality', 'tumor_cell_cd30+',\\\n",
    "                                        'large_cell_transformation', 'ldh_u_l', 'wbc_103_μl', 'rbc_106_μl',\\\n",
    "                                        'hematocrit_%', 'mcv_fl', 'mchc_g_dl', 'rdw_%', 'platelet_count_103_μl',\\\n",
    "                                        'segmented_neutrophil,_absolute_103_μl', 'lymphocyte,_absolute_103_μl',\\\n",
    "                                        'monocytes,_absolute_103_μl', 'eosinophils,_absolute_103_μl',\\\n",
    "                                        'basophils,_absolute_103_μl', 'segmented_neutrophils_%', 'lymphocytes_%',\\\n",
    "                                        'monocytes_%', 'eosinophils_%', 'basophils_%']])\n",
    "\n",
    "# 'predominant_lesion_type_at_diagnosis', \n",
    "# 't', 'n', 'm', 'b', \n",
    "# 'eosinophils,_absolute_103_μl'\n",
    "\n",
    "\n",
    "#wbc_103mul\n",
    "#rbc_106ml\n",
    "#nuetrophil_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN YES/NO & POSITIVE/NEGATIVE TO DUMMIES\n",
    "df_clin_updated_lean['lymph_node_biopsy_performed'] = \\\n",
    "df_clin_updated_lean['lymph_node_biopsy_performed'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['family_history_of_leukemia_lymphoma'] = \\\n",
    "df_clin_updated_lean['family_history_of_leukemia_lymphoma'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['tumor_cell_cd30+'] = \\\n",
    "df_clin_updated_lean['tumor_cell_cd30+'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['large_cell_transformation'] = \\\n",
    "df_clin_updated_lean['large_cell_transformation'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['tcr_clonality'] = \\\n",
    "df_clin_updated_lean['tcr_clonality'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "df_clin_updated_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'] = \\\n",
    "df_clin_updated_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109d752",
   "metadata": {},
   "source": [
    "### df_lean: Preprocessed Genetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb146ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Preprocessed Genetic Data\n",
    "df_lean = pd.read_csv ('stats_by_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK CLINICAL DATA BASICS\n",
    "df_clin_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM SAMPLE ID TOJOIN TO CLINICAL DATA\n",
    "df_lean['sample_id'] = df_lean['sample_id'].apply(lambda x: re.sub('_', '-', x[:5]) if 'WES' in x else\\\n",
    "                                                  (x[:-10] if 'CTCL' in x else \\\n",
    "                                                  (x[:-13] if 'almeida' in x else\\\n",
    "                                                  ((x[-2:]+x[:-2])[:-15] if 'ungewickell' in x else\\\n",
    "                                                  ('-'.join([ele.lstrip('0').lower() for ele in x[:-10].split('-')]) if 'SPZ' in x else x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af39d9",
   "metadata": {},
   "source": [
    "# Merge (Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131081ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE tbe updated CLINICAL, GENETIC DATA\n",
    "df_all_updated = pd.merge(df_lean, df_clin_updated_lean, on='sample_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPUTATION; \"UNKNOWN\" FOR CATEGORICAL, MEAN FILL-IN FOR CONTINUOUS\n",
    "for col in df_clin_updated_lean.columns:\n",
    "    if col in ['race', 'gender', 'country_of_residence', 'ethnicity', 'predominant_lesion_type_at_diagnosis', 't', \n",
    "              'n', 'm', 'b']:\n",
    "        df_all_updated[col] = df_all_updated[col].fillna('unknown')\n",
    "    elif col != 'sample_id':\n",
    "        df_all_updated[col] = df_all_updated[col].fillna(np.mean(df_all_updated[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DUMMIES FOR CATEGORICALS\n",
    "df_all_updated = pd.get_dummies(df_all_updated, columns = ['race', 'gender', 'country_of_residence', 'ethnicity', \n",
    "                                                          'predominant_lesion_type_at_diagnosis', 't', 'n', 'm', 'b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_updated['sample_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee39532",
   "metadata": {},
   "source": [
    "# Defining Features and Labels - For updated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc781e4",
   "metadata": {},
   "source": [
    "## Yale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_y = df_all_updated[df_all_updated['sample_id'].str.contains(\"CTCL\")== False]\n",
    "X_test_y = df_all_updated[df_all_updated['sample_id'].str.contains(\"CTCL\")== True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf906943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE STANDARDSCALER FOR LATER USE\n",
    "std_scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define (Scaled/Normalized) Features and Labels\n",
    "X_new_y = X_train_y.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_new_scaled_y = std_scl.fit_transform(X_new_y)\n",
    "X_new_norm_y = normalize(X_new_y)\n",
    "\n",
    "y_new_y = X_train_y.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc540a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_yale = X_test_y.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_test_scaled_y = std_scl.transform(X_test_yale)\n",
    "X_test_norm_y = normalize(X_test_yale)\n",
    "\n",
    "y_test_yale = X_test_y.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed3311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_y['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_y['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67067477",
   "metadata": {},
   "source": [
    "## IMM - Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = df_all_updated[df_all_updated['sample_id'].str.contains(\"prasad\")== False]\n",
    "X_test_b = df_all_updated[df_all_updated['sample_id'].str.contains(\"prasad\")== True]\n",
    "\n",
    "# Define (Scaled/Normalized) Features and Labels\n",
    "X_new_b = X_train_b.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_new_scaled_b = std_scl.fit_transform(X_new_b)\n",
    "X_new_norm_b = normalize(X_new_b)\n",
    "y_new_b = X_train_b.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])\n",
    "\n",
    "\n",
    "X_test_bar = X_test_b.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_test_scaled_bar = std_scl.transform(X_test_bar)\n",
    "X_test_norm_bar = normalize(X_test_bar)\n",
    "y_test_bar = X_test_b.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6cd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_b['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa65e1e",
   "metadata": {},
   "source": [
    "## Kings College"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k = df_all_updated[df_all_updated['sample_id'].str.contains(\"WES\")== False]\n",
    "X_test_k = df_all_updated[df_all_updated['sample_id'].str.contains(\"WES\")== True]\n",
    "\n",
    "# Define (Scaled/Normalized) Features and Labels\n",
    "X_new_k = X_train_k.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_new_scaled_k = std_scl.fit_transform(X_new_k)\n",
    "X_new_norm_k = normalize(X_new_k)\n",
    "y_new_k = X_train_k.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])\n",
    "\n",
    "\n",
    "X_test_kings = X_test_k.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_test_scaled_kings = std_scl.transform(X_test_kings)\n",
    "X_test_norm_kings = normalize(X_test_kings)\n",
    "y_test_kings = X_test_k.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_k['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fe2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test_kings))\n",
    "print(len(y_test_bar))\n",
    "print(len(y_test_yale))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eac5e6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a116717",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bce0d1",
   "metadata": {},
   "source": [
    "#### Yale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efcfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost n_estimator = 400\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=400, learning_rate = 1, algorithm = \"SAMME.R\")\n",
    "\n",
    "model_ada.fit(X_new_y, y_new_y)\n",
    "y_pred = model_ada.predict(X_test_yale)\n",
    "\n",
    "ada_acc_scores = accuracy_score(y_test_yale, y_pred)\n",
    "ada_prec_scores = precision_score(y_test_yale, y_pred)\n",
    "\n",
    "print(\"AdaBoost without PCA\")\n",
    "print('Accuracy: ', ada_acc_scores)\n",
    "print('Precision: ', ada_prec_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(y_test_yale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test_yale))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b21a23",
   "metadata": {},
   "source": [
    "#### Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1fd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost n_estimator = 400\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=400, learning_rate = 1, algorithm = \"SAMME.R\")\n",
    "\n",
    "model_ada.fit(X_new_b, y_new_b)\n",
    "y_pred = model_ada.predict(X_test_bar)\n",
    "\n",
    "ada_acc_scores = accuracy_score(y_test_bar, y_pred)\n",
    "ada_prec_scores = precision_score(y_test_bar, y_pred)\n",
    "\n",
    "print(\"AdaBoost without PCA\")\n",
    "print('Accuracy: ', ada_acc_scores)\n",
    "print('Precision: ', ada_prec_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffa9f1",
   "metadata": {},
   "source": [
    "#### Kings College"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost n_estimator = 400\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model_ada = AdaBoostClassifier(n_estimators=400, learning_rate = 1, algorithm = \"SAMME.R\")\n",
    "\n",
    "model_ada.fit(X_new_k, y_new_k)\n",
    "y_pred = model_ada.predict(X_test_kings)\n",
    "\n",
    "ada_acc_scores = accuracy_score(y_test_kings, y_pred)\n",
    "ada_prec_scores = precision_score(y_test_kings, y_pred)\n",
    "\n",
    "print(\"AdaBoost without PCA\")\n",
    "print('Accuracy: ', ada_acc_scores)\n",
    "print('Precision: ', ada_prec_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3baf3a",
   "metadata": {},
   "source": [
    "### Ramdom Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33900c8",
   "metadata": {},
   "source": [
    "#### Yale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd60a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('pca', PCA(n_components=12)), ('m', ens.RandomForestClassifier(n_estimators = 500, criterion = \"entropy\"))]\n",
    "model_rf = Pipeline(steps = steps)\n",
    "\n",
    "model_rf.fit(X_new_y, y_new_y)\n",
    "y_pred = model_rf.predict(X_test_yale)\n",
    "\n",
    "rf_acc_scores = accuracy_score(y_test_yale, y_pred)\n",
    "rf_prec_scores = precision_score(y_test_yale, y_pred)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print('n_components: 12, accuracy: ', rf_acc_scores)\n",
    "print('n_components: 12, precision: ', rf_prec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f727fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(y_test_yale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f835f6",
   "metadata": {},
   "source": [
    "#### Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbebbd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RF\n",
    "steps = [('pca', PCA(n_components=12)), ('m', ens.RandomForestClassifier(n_estimators = 500, criterion = \"entropy\"))]\n",
    "model_rf = Pipeline(steps = steps)\n",
    "\n",
    "model_rf.fit(X_new_b, y_new_b)\n",
    "y_pred = model_rf.predict(X_test_bar)\n",
    "\n",
    "rf_acc_scores = accuracy_score(y_test_bar, y_pred)\n",
    "rf_prec_scores = precision_score(y_test_bar, y_pred)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print('n_components: 12, accuracy: ', rf_acc_scores)\n",
    "print('n_components: 12, precision: ', rf_prec_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c5559",
   "metadata": {},
   "source": [
    "#### Kings College"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "steps = [('pca', PCA(n_components=12)), ('m', ens.RandomForestClassifier(n_estimators = 500, criterion = \"entropy\"))]\n",
    "model_rf = Pipeline(steps = steps)\n",
    "\n",
    "model_rf.fit(X_new_k, y_new_k)\n",
    "y_pred = model_rf.predict(X_test_kings)\n",
    "\n",
    "rf_acc_scores = accuracy_score(y_test_kings, y_pred)\n",
    "rf_prec_scores = precision_score(y_test_kings, y_pred)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print('n_components: 12, accuracy: ', rf_acc_scores)\n",
    "print('n_components: 12, precision: ', rf_prec_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73163cc9",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a8d70",
   "metadata": {},
   "source": [
    "#### Yale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_xg = XGBClassifier(eta = 0.1, max_depth = 4, scale_pos_weight = 0.25, \n",
    "                         eval_metric = \"error\", use_label_encoder = False)\n",
    "\n",
    "model_xg.fit(X_new_y, y_new_y)\n",
    "y_pred = model_xg.predict(X_test_yale)\n",
    "\n",
    "xg_acc_scores = accuracy_score(y_test_yale, y_pred)\n",
    "xg_prec_scores = precision_score(y_test_yale, y_pred)\n",
    "\n",
    "print(\"XGBoost without PCA\")\n",
    "print('Accuracy: ', xg_acc_scores)\n",
    "print('Precision: ', xg_prec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f19e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel(y_test_yale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe84cc1",
   "metadata": {},
   "source": [
    "#### Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_xg = XGBClassifier(eta = 0.1, max_depth = 4, scale_pos_weight = 0.25, \n",
    "                         eval_metric = \"error\", use_label_encoder = False)\n",
    "\n",
    "model_xg.fit(X_new_b, y_new_b)\n",
    "y_pred = model_xg.predict(X_test_bar)\n",
    "\n",
    "xg_acc_scores = accuracy_score(y_test_bar, y_pred)\n",
    "xg_prec_scores = precision_score(y_test_bar, y_pred)\n",
    "\n",
    "print(\"XGBoost without PCA\")\n",
    "print('Accuracy: ', xg_acc_scores)\n",
    "print('Precision: ', xg_prec_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac2729",
   "metadata": {},
   "source": [
    "#### Kings College"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264aa51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_xg = XGBClassifier(eta = 0.1, max_depth = 4, scale_pos_weight = 0.25, \n",
    "                         eval_metric = \"error\", use_label_encoder = False)\n",
    "\n",
    "model_xg.fit(X_new_k, y_new_k)\n",
    "y_pred = model_xg.predict(X_test_kings)\n",
    "\n",
    "xg_acc_scores = accuracy_score(y_test_kings, y_pred)\n",
    "xg_prec_scores = precision_score(y_test_kings, y_pred)\n",
    "\n",
    "print(\"XGBoost without PCA\")\n",
    "print('Accuracy: ', xg_acc_scores)\n",
    "print('Precision: ', xg_prec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03943fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
