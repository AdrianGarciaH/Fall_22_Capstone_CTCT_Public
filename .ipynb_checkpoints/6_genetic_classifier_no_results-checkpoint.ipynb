{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model as lm, metrics, ensemble as ens\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE, RFECV, SequentialFeatureSelector\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING A FUNCTION TO UPDATE COLUMN NAMES LATER\n",
    "def lower_no_space(word): \n",
    "    \n",
    "    word = re.sub(' ', '_', word) \n",
    "    \n",
    "    word = re.sub(r'\\'', '', word) \n",
    "    \n",
    "    word = re.sub(r'\\(', '', word)\n",
    "    \n",
    "    word = re.sub(r'\\)', '', word)\n",
    "    \n",
    "    word = re.sub('\\?', '', word)\n",
    "    \n",
    "    word = re.sub('/', '_', word)\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ IN Updated CLINICAL DATA FOR LATER USE (CONVERTED TO .csv IN GOOGLE SHEETS)\n",
    "df_clin_updated = pd.read_csv(\"Homebase_new_updated.csv\", header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAMING COLUMNS\n",
    "df_clin_updated = df_clin_updated.rename(mapper = lower_no_space, axis = 1) \n",
    "df_clin_updated.rename(columns={'subject_sample_id':'sample_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the age at initial diagnosis from date of birth and date_of_initial_diagnosis\n",
    "df_clin_updated['date_of_birth'] = pd.to_datetime(df_clin_updated['date_of_birth'])\n",
    "df_clin_updated['date_of_initial_diagnosis'] = pd.to_datetime(df_clin_updated['date_of_initial_diagnosis'])\n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = (pd.DatetimeIndex(df_clin_updated['date_of_initial_diagnosis']).year \n",
    "                        - pd.DatetimeIndex(df_clin_updated['date_of_birth']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the abnormal in date of birth from the Stanford data, \n",
    "#Remove the age at initial diagonosis for data from Stanford & the one that has negative age \n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = np.where(df_clin_updated['data_access_group'] == 'Stanford', np.nan, df_clin_updated[\"age_at_initial_diagnosis\"])\n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = np.where(df_clin_updated[\"age_at_initial_diagnosis\"] < 0, np.nan, df_clin_updated[\"age_at_initial_diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data type: date_of_birth, n, m \n",
    "df_clin_updated = df_clin_updated.astype({'t':'object', 'b':'object'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TONS OF DATA, PULL WHAT WE WANT\n",
    "df_clin_updated_lean = df_clin_updated.drop(columns = [x for x in df_clin_updated.columns if x not in ['gender', 'race', \\\n",
    "                                       'country_of_residence', 'sample_id', 'ethnicity',\\\n",
    "                                        'age_at_initial_diagnosis', 't', 'n', 'm', 'b',\\\n",
    "                                        'predominant_lesion_type_at_diagnosis','lymph_node_biopsy_performed',\\\n",
    "                                        'family_history_of_leukemia_lymphoma', \\\n",
    "                                        'has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical',\\\n",
    "                                        'cd4+:cd8+_ratio', 'total_lymphocyte_count', 'absolute_cd4+_count_per_ul',\\\n",
    "                                        '%cd4+cd26-', '%cd4+cd7-', 'tcr_clonality', 'tumor_cell_cd30+',\\\n",
    "                                        'large_cell_transformation', 'ldh_u_l', 'wbc_103_μl', 'rbc_106_μl',\\\n",
    "                                        'hematocrit_%', 'mcv_fl', 'mchc_g_dl', 'rdw_%', 'platelet_count_103_μl',\\\n",
    "                                        'segmented_neutrophil,_absolute_103_μl', 'lymphocyte,_absolute_103_μl',\\\n",
    "                                        'monocytes,_absolute_103_μl', 'eosinophils,_absolute_103_μl',\\\n",
    "                                        'basophils,_absolute_103_μl', 'segmented_neutrophils_%', 'lymphocytes_%',\\\n",
    "                                        'monocytes_%', 'eosinophils_%', 'basophils_%']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN YES/NO & POSITIVE/NEGATIVE TO DUMMIES\n",
    "df_clin_updated_lean['lymph_node_biopsy_performed'] = \\\n",
    "df_clin_updated_lean['lymph_node_biopsy_performed'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['family_history_of_leukemia_lymphoma'] = \\\n",
    "df_clin_updated_lean['family_history_of_leukemia_lymphoma'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['tumor_cell_cd30+'] = \\\n",
    "df_clin_updated_lean['tumor_cell_cd30+'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['large_cell_transformation'] = \\\n",
    "df_clin_updated_lean['large_cell_transformation'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['tcr_clonality'] = \\\n",
    "df_clin_updated_lean['tcr_clonality'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "df_clin_updated_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'] = \\\n",
    "df_clin_updated_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Preprocessed Genetic Data\n",
    "df_lean = pd.read_csv ('stats_by_sample.csv', index_col = 0)\n",
    "df_lean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM SAMPLE ID TO JOIN TO CLINICAL DATA\n",
    "df_lean['sample_id'] = df_lean['sample_id'].apply(lambda x: re.sub('_', '-', x[:5]) if 'WES' in x else\\\n",
    "                                                  (x[:-10] if 'CTCL' in x else \\\n",
    "                                                  (x[:-13] if 'almeida' in x else\\\n",
    "                                                  ((x[-2:]+x[:-2])[:-15] if 'ungewickell' in x else\\\n",
    "                                                  ('-'.join([ele.lstrip('0').lower() for ele in x[:-10].split('-')]) if 'SPZ' in x else x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE tbe updated CLINICAL, GENETIC DATA\n",
    "df_all_updated = pd.merge(df_lean, df_clin_updated_lean, on='sample_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPUTATION; \"UNKNOWN\" FOR CATEGORICAL, MEAN FILL-IN FOR CONTINUOUS\n",
    "for col in df_clin_updated_lean.columns:\n",
    "    if col in ['race', 'gender', 'country_of_residence', 'ethnicity', 'predominant_lesion_type_at_diagnosis', 't', \n",
    "              'n', 'm', 'b']:\n",
    "        df_all_updated[col] = df_all_updated[col].fillna('unknown')\n",
    "    elif col != 'sample_id':\n",
    "        df_all_updated[col] = df_all_updated[col].fillna(np.mean(df_all_updated[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DUMMIES FOR CATEGORICALS\n",
    "df_all_updated = pd.get_dummies(df_all_updated, columns = ['race', 'gender', 'country_of_residence', 'ethnicity', 'predominant_lesion_type_at_diagnosis', \n",
    "                                                          't', 'n', 'm', 'b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WRITE A PROGRAM TO CHANGE THE MF/SS GENETIC DATA LARRY\n",
    "# df_ss = pd.read_csv(\"ss_gen_data.csv\", header = 2)\n",
    "# df_mf = pd.read_csv(\"mf_gen_data.csv\", header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RENAMING COLUMNS\n",
    "# df_ss = df_ss.rename(mapper = lower_no_space, axis = 1) \n",
    "\n",
    "# #AND AGAIN\n",
    "# df_mf = df_mf.rename(mapper = lower_no_space, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen = pd.read_csv(\"full_gen.csv\") #SEE GEN_DF_SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spz-10, spz-6, spz-5, spz-9, spz-11, spz-17, spz-29, spz-19, spz-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen['outcome'] = df_gen['sample_id'].apply(lambda x: 1 if (x in set(df_ss['sample_id'])) & \\\n",
    "#                                               (x not in ['SPZ-010__wang__SS', 'SPZ-006__wang__SS', \\\n",
    "#                                                          'SPZ-005__wang__SS', 'SPZ-009__wang__SS', \\\n",
    "#                                                          'SPZ-011__wang__SS', 'SPZ-017__wang__SS', \\\n",
    "#                                                          'SPZ-029__wang__SS', 'SPZ-019__wang__SS', \\\n",
    "#                                                          'SPZ-027__wang__SS'])\n",
    "#                                               else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen = df_gen[df_gen['chrom'] != 'Chromosome']\n",
    "# df_gen = df_gen[df_gen['gene_symbol'] != '#version 2.4'] #WEIRD OBS IN DATA\n",
    "# df_gen['chrom'] = df_gen['chrom'].apply(lambda x: '19' if 'gl000209' in str(x) else str(x)) #WEIRD OBS AGAIN\n",
    "# df_gen = df_gen.drop(columns = ['phred']) #USING ONLY RAWSCORE FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen['pos'] = df_gen['pos'].astype('float')\n",
    "# df_gen = df_gen[~df_gen['pos'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # num_sections = m.ceil(np.max((df_gen['pos'].values.tolist()))/10000000)\n",
    "# #^^CAN USE TO DOUBLE CHECK THAT WE HAVE THE RIGHT NUMBER OF SECTIONS\n",
    "\n",
    "# df_gen['section'] = df_gen['pos'].apply(lambda x: m.ceil(x/1000000))\n",
    "# df_gen['section'] = df_gen['section'].astype('string')\n",
    "# df_gen['section'] = df_gen['section'].astype('string') + '_' + 'chrom' + '_' + df_gen['chrom']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #CHECK GENERAL SHAPE\n",
    "# df_gen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CREATING VAR W/ NEG SCORES = 0;\n",
    "# #SITE SAYS NEG SCORE MEANS VERY UNLIKELY TO BE HARMFUL, SO I COULD SEE THEM NOT \"OFFSETTING\" HIGH POSITIVE SCORES\n",
    "# #SO, WANT TO TRY ONE WHERE THEY WON'T WHEN SUMMING OVER A LARGER AREA\n",
    "# df_gen['non_neg_rawscore'] = df_gen['rawscore'].apply(lambda x: 0 if x <= 0 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GOING TO USE A SERIES OF PIVOTS TO MAKE A LEANER DF\n",
    "# def make_spec_pivot(magnitude, score, function, name):\n",
    "#     #THESE ARE THE \"LEVELS\" ON WHICH WE WANT AGGED SCORES\n",
    "#     if magnitude == 'gene_symbol':\n",
    "#         prefix = 'gene_'\n",
    "#     elif magnitude == 'chrom':\n",
    "#         prefix = 'chromosome_'\n",
    "#     elif magnitude == 'section':\n",
    "#         prefix = 'section_'\n",
    "    \n",
    "#     #DON'T WANT TO CHANGE ORIGINAL DF\n",
    "#     df = df_gen.copy()\n",
    "    \n",
    "#     #GET JUST PERSON, \"LEVEL\", SCORE\n",
    "#     df = df.drop(columns = [x for x in df.columns if x != 'sample_id' and\\\n",
    "#                                 x != magnitude and x != score])\n",
    "    \n",
    "#     #RESHAPE DATAFRAME\n",
    "#     df = df.pivot_table(index = 'sample_id', columns = [magnitude], values = [score], aggfunc = function).reset_index()\n",
    "#     df.reset_index(inplace = True)\n",
    "    \n",
    "#     #RENAME RESULTING COLUMNS\n",
    "#     df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "#     df = df.drop(columns = ['index'])\n",
    "    \n",
    "#     #USING GENERAL LOGIC I FOUND ONLINE, ADJUSTING FOR SPECIFIC OUTPUT OF SUMS VS. PERCENTILES\n",
    "#     if name == 'sum':\n",
    "#         if score == 'rawscore':\n",
    "#             df.columns = [prefix + x[9:] + '_' + x[:8] if 'score' in x else x for x in df.columns]\n",
    "#         else:\n",
    "#             df.columns = [prefix + x[17:] + '_' + x[:16] if 'score' in x else x for x in df.columns]\n",
    "#     elif name == 'nty':\n",
    "#         if score == 'rawscore':\n",
    "#             df.columns = ['nty_' + prefix + x[9:] + '_' + x[:8] if 'score' in x else x for x in df.columns]\n",
    "#         else:\n",
    "#             df.columns = ['nty_' + prefix + x[17:] + '_' + x[:16] if 'score' in x else x for x in df.columns]\n",
    "#     elif name == 'med':\n",
    "#         if score == 'rawscore':\n",
    "#             df.columns = ['med_' + prefix + x[9:] + '_' + x[:8] if 'score' in x else x for x in df.columns]\n",
    "#         else:\n",
    "#             df.columns = ['med_' + prefix + x[17:] + '_' + x[:16] if 'score' in x else x for x in df.columns]\n",
    "    \n",
    "#     #IMPUTING 0s FOR NULLS\n",
    "#     df = df.fillna(0)\n",
    "#     return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GET INITIAL LEAN DF FOR FOUNDATION, USING GENE-LEVEL SCORES SUMMED\n",
    "# df_lean = pd.merge(make_spec_pivot('gene_symbol', 'rawscore', np.sum, 'sum'),\\\n",
    "#                    make_spec_pivot('gene_symbol', 'non_neg_rawscore', np.sum, 'sum'),\\\n",
    "#                    on=['sample_id'])\n",
    "\n",
    "# #ADD CHROMSOME/SECTION LEVEL STATS\n",
    "# for mag in ['chrom', 'section']:\n",
    "    \n",
    "#     #BOTH SCORE TYPES\n",
    "#     for scr in ['rawscore', 'non_neg_rawscore']:\n",
    "        \n",
    "#         #SUMS AND MEDIANS\n",
    "#         for func in [np.sum, lambda x: np.percentile(x, 50)]:\n",
    "#             if func == np.sum:\n",
    "#                 nm = 'sum'\n",
    "#             elif func != np.sum:\n",
    "#                 nm = 'med'\n",
    "            \n",
    "#             #SEE FUNC DEF ABOVE\n",
    "#             df_latest = make_spec_pivot(mag, scr, func, nm)\n",
    "            \n",
    "#             #ADD OUTPUT TO CURRENT LEAN DF\n",
    "#             df_lean = pd.merge(df_lean, df_latest, on = ['sample_id'])\n",
    "\n",
    "# #HAD HARD TIME GETTING 90TH PCTL TO WORK IN FOR LOOP SO JUST GAVE IT ITS OWN SECTION\n",
    "# for scr in ['rawscore', 'non_neg_rawscore']:\n",
    "#     df_latest = make_spec_pivot('chrom', scr, lambda x: np.percentile(x, 90), 'nty')\n",
    "#     df_lean = pd.merge(df_lean, df_latest, on = ['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ALSO WANT #OF MUTATIONS ON CHROMOSOME; UPDATE CODE FOR EFFICIENCY LATER\n",
    "# for chrom in set(list(df_gen['chrom'].values)):\n",
    "#     df_lean['chromosome_' + str(chrom) + '_mutations'] = df_lean['sample_id'].apply(lambda x:\\\n",
    "#                                                                                len(df_gen[(df_gen['sample_id'] == x)\\\n",
    "#                                                                                    & (df_gen['chrom'] == chrom)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ABOVE TRANSFORMATIONS DROPPED OUTCOME VAR FOR SAMPLE IDs, RE-ADDING HERE\n",
    "# df_outcome = df_gen.copy()\n",
    "# df_outcome = df_outcome.drop(columns = [x for x in df_outcome.columns if 'sample_id' not in x and\\\n",
    "#                                        'outcome' not in x])\n",
    "# df_outcome = df_outcome.drop_duplicates()\n",
    "# df_lean = pd.merge(df_lean, df_outcome, on = ['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DROP ONE EACH OF GENE, SECTION, CHROMOSOME SCORE FOR COLINEARITY \n",
    "# df_lean = df_lean.drop(columns = [\\\n",
    "# random.choice([x for x in df_lean.columns if 'gene_' in x and 'non_neg_rawscore' in x]),\\\n",
    "# random.choice([x for x in df_lean.columns if 'gene_' in x and 'rawscore' in x and 'non_neg' not in x]),\\\n",
    "# random.choice([x for x in df_lean.columns if 'section_' in x and 'non_neg_rawscore' in x]),\\\n",
    "# random.choice([x for x in df_lean.columns if 'section_' in x and 'rawscore' in x and 'non_neg' not in x]),\\\n",
    "# random.choice([x for x in df_lean.columns if 'chromosome_' in x and 'non_neg_rawscore' in x]),\\\n",
    "# random.choice([x for x in df_lean.columns if 'chromosome_' in x and 'rawscore' in x and 'non_neg' not in x])                             \n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # USING 0 FILL IN FOR SCORES (NO SCORES MEANS NO MUTATION, PRESUMABLY)\n",
    "# for col in df_lean.columns:\n",
    "#     if 'rawscore' in col:\n",
    "#         df_lean[col] = df_lean[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lean = df_lean.drop(columns = [x for x in df_lean.columns if 'chromosome_nan' in x]) #WEIRD ONEOFF, CAN'T EXPLAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE A CSV WITH NEW DF\n",
    "# df_lean.to_csv(\"stats_by_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK DF BASICS\n",
    "# df_lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lean['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT RF FI FUNCTION I FOUND ONLINE\n",
    "def plot_feature_importance(importance, names, model_type, name, threshold):\n",
    "    \n",
    "    #Create arrays from freature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    #CREATE A DATAFRAME USING A DICTIONARY\n",
    "    data = {'feature_names': feature_names, 'feature_importance': feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    #SORT THE DF IN ORDER DECREASING FI\n",
    "    fi_df.sort_values(by = ['feature_importance'], ascending = False, inplace = True)\n",
    "    \n",
    "    #filter\n",
    "    fi_df = fi_df[fi_df['feature_importance'] >= threshold]\n",
    "    \n",
    "    #DEFINE SIZE OF BAR PLOT\n",
    "    plt.figure(figsize = (5, 6))\n",
    "    \n",
    "    #PLOT SEABORN BAR CHART\n",
    "    sns.barplot(x = fi_df['feature_importance'], y = fi_df['feature_names'])\n",
    "    \n",
    "    #ADD CHART LABELS\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "    plt.savefig(name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TRANSFORM SAMPLE ID TO JOIN TO CLINICAL DATA\n",
    "# df_lean['sample_id'] = df_lean['sample_id'].apply(lambda x: re.sub('_', '-', x[:5]) if 'WES' in x else\\\n",
    "#                                                   (x[:-10] if 'CTCL' in x else \\\n",
    "#                                                    ('-'.join([ele.lstrip('0').lower() for ele in x[:-10].split('-')]) if 'SPZ' in x else x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clin[df_clin['clinical_subtype_or_variant'] != 'Sezary syndrome']['predominant_lesion_type_at_diagnosis'].value_counts()\n",
    "# df_clin['clinical_subtype_or_variant'].value_counts()\n",
    "# SS - Patch = 14, Erythroderma = 12, Plaque = 2, Tumor = 1\n",
    "# MF - Patch = = 6, Erhthroderma = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_clin.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK CLINICAL DATA BASICS\n",
    "# df_clin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TONS OF DATA, PULL WHAT WE WANT\n",
    "# df_clin_lean = df_clin.drop(columns = [x for x in df_clin.columns if x not in ['gender', 'race', \\\n",
    "#                                        'country_of_residence', 'sample_id', 'ethnicity',\\\n",
    "#                                         'age_at_initial_diagnosis', 't', 'n', 'm', 'b',\\\n",
    "#                                         'predominant_lesion_type_at_diagnosis','lymph_node_biopsy_performed',\\\n",
    "#                                         'family_history_of_leukemia_lymphoma', \\\n",
    "#                                         'has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical',\\\n",
    "#                                         'cd4+:cd8+_ratio', 'total_lymphocyte_count', 'absolute_cd4+_count_per_ul',\\\n",
    "#                                         '%cd4+cd26-', '%cd4+cd7-', 'tcr_clonality', 'tumor_cell_cd30+',\\\n",
    "#                                         'large_cell_transformation', 'ldh_u_l', 'wbc_103_μl', 'rbc_106_μl',\\\n",
    "#                                         'hematocrit_%', 'mcv_fl', 'mchc_g_dl', 'rdw_%', 'platelet_count_103_μl',\\\n",
    "#                                         'segmented_neutrophil,_absolute_103_μl', 'lymphocyte,_absolute_103_μl',\\\n",
    "#                                         'monocytes,_absolute_103_μl', 'eosinophils,_absolute_103_μl',\\\n",
    "#                                         'basophils,_absolute_103_μl', 'segmented_neutrophils_%', 'lymphocytes_%',\\\n",
    "#                                         'monocytes_%', 'eosinophils_%', 'basophils_%']])\n",
    "                                       \n",
    "                                       \n",
    "                                       \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clin_lean['lymph_node_biopsy_performed'] = \\\n",
    "# df_clin_lean['lymph_node_biopsy_performed'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# df_clin_lean['family_history_of_leukemia_lymphoma'] = \\\n",
    "# df_clin_lean['family_history_of_leukemia_lymphoma'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# df_clin_lean['tumor_cell_cd30+'] = \\\n",
    "# df_clin_lean['tumor_cell_cd30+'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# df_clin_lean['large_cell_transformation'] = \\\n",
    "# df_clin_lean['large_cell_transformation'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# df_clin_lean['tcr_clonality'] = \\\n",
    "# df_clin_lean['tcr_clonality'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "# df_clin_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'] = \\\n",
    "# df_clin_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE CLINICAL, GENETIC DATA\n",
    "# df_all = pd.merge(df_lean, df_clin_lean, on='sample_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_clin_lean.columns:\n",
    "#     if col in ['race', 'gender', 'country_of_residence', 'ethnicity', 'predominant_lesion_type_at_diagnosis', 't', \n",
    "#               'n', 'm', 'b']:\n",
    "#         df_all[col] = df_all[col].fillna('unknown')\n",
    "#     elif col != 'sample_id':\n",
    "#         df_all[col] = df_all[col].fillna(np.mean(df_all[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IMPUTATION; \"UNKNOWN\" FOR CATEGORICAL, MEAN FILL-IN FOR CONTINUOUS\n",
    "# df_all['race'] = df_all['race'].fillna('unknown')\n",
    "# df_all['gender'] = df_all['gender'].fillna('unknown')\n",
    "# df_all['country_of_residence'] = df_all['country_of_residence'].fillna('unknown')\n",
    "# df_all['ethnicity'] = df_all['ethnicity'].fillna('unknown')\n",
    "# df_all['lymph_node_biopsy_performed'] = df_all['lymph_node_biopsy_performed'].fillna('unknown')\n",
    "# df_all['predominant_lesion_type_at_diagnosis'] = df_all['predominant_lesion_type_at_diagnosis'].fillna('unknown')\n",
    "# df_all['age_at_initial_diagnosis'] = df_all['age_at_initial_diagnosis'].fillna(np.mean(df_clin_lean['age_at_initial_diagnosis']))\n",
    "# df_all['t'] = df_all['t'].fillna(np.mean(df_clin_lean['t']))\n",
    "# df_all['n'] = df_all['n'].fillna(np.mean(df_clin_lean['n']))\n",
    "# df_all['m'] = df_all['m'].fillna(np.mean(df_clin_lean['m']))\n",
    "# df_all['b'] = df_all['b'].fillna(np.mean(df_clin_lean['b']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[df_all['outcome'] == 0]['predominant_lesion_type_at_diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GET DUMMIES FOR CATEGORICALS\n",
    "# df_all = pd.get_dummies(df_all, columns = ['race', 'gender', 'country_of_residence', 'ethnicity',\\\n",
    "#                                            'predominant_lesion_type_at_diagnosis', 't', 'n', 'm', 'b'])\n",
    "# # df_all.to_csv(\"stats_by_sample.csv\")\n",
    "# #DEFINE STANDARDSCALER FOR LATER USE\n",
    "# # std_scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_updated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_updated = df_all_updated.drop(columns = [x for x in df_all_updated.columns if ('rawscore' in x and 'non_neg' not in x)])\n",
    "df_all_updated = df_all_updated.drop(columns = [x for x in df_all_updated.columns if 'med_' in x or 'nty' in x])\n",
    "\n",
    "# std_scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE STANDARDSCALER FOR LATER USE\n",
    "std_scl = StandardScaler()\n",
    "\n",
    "# Define (Scaled/Normalized) Features and Labels\n",
    "X_new = df_all_updated.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_new_scaled = std_scl.fit_transform(X_new)\n",
    "X_new_norm = normalize(X_new)\n",
    "\n",
    "y_new = df_all_updated.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_updated['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Version\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = lm.LogisticRegression()\n",
    "acc_scores = cross_val_score(log, X_new_scaled, y_new.values.ravel(), scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(log, X_new_scaled, y_new.values.ravel(), scoring='precision', cv=rskf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('std for accuracy: ', np.std(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))\n",
    "print('std for precision: ', np.std(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST (rskf)\n",
    "rf = ens.RandomForestClassifier()\n",
    "acc_scores = cross_val_score(rf, X_new, y_new.values.ravel(), scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(rf, X_new, y_new.values.ravel(), scoring='precision', cv=rskf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('std for accuracy: ', np.std(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))\n",
    "print('std for precision: ', np.std(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIDGE\n",
    "rdg = lm.RidgeClassifier()\n",
    "acc_scores = cross_val_score(rdg, X_new_norm, y_new.values.ravel(), scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(rdg, X_new_norm, y_new.values.ravel(), scoring='precision', cv=rskf, n_jobs=-1)\n",
    "print('ridge accuracy: ', np.mean(acc_scores))\n",
    "print('std for accuracy: ', np.std(acc_scores))\n",
    "print('ridge precision: ', np.mean(prec_scores))\n",
    "print('std for precision: ', np.std(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "for kern in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    \n",
    "    svc = SVC(kernel = kern, probability = True)\n",
    "    \n",
    "    acc_scores = cross_val_score(svc, X_new_norm, y_new.values.ravel(), scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(svc, X_new_norm, y_new.values.ravel(), scoring='precision', cv=rskf, n_jobs=-1)\n",
    "    print(kern, ' accuracy: ', np.mean(acc_scores))\n",
    "    print(kern, ' std for accuracy: ', np.std(acc_scores))\n",
    "    print(kern, ' precision: ', np.mean(prec_scores))\n",
    "    print(kern, ' std for precision: ', np.std(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = XGBClassifier(eval_metric = \"error\", use_label_encoder = False)\n",
    "acc_scores = cross_val_score(model, X_new, y_new.values.ravel(), scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(model, X_new, y_new.values.ravel(), scoring='precision', cv=rskf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('std for accuracy: ', np.std(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))\n",
    "print('std for precision: ', np.std(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada Boost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "acc_scores = cross_val_score(model, X_new, y_new.values.ravel(), scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(model, X_new, y_new.values.ravel(), scoring='precision', cv=rskf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('std for accuracy: ', np.std(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))\n",
    "print('std for precision: ', np.std(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kern in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    \n",
    "    svc = SVC(kernel = kern, probability = True)\n",
    "    \n",
    "    acc_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(kern, ' accuracy: ', np.mean(acc_scores))\n",
    "    print(kern, ' precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY DROPPING GENES FOR RISK OF OVERFITTING\n",
    "df_sect_only = df_all_updated.copy()\n",
    "df_sect_only = df_sect_only.drop(columns = [x for x in df_sect_only.columns if 'gene_'  in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = df_sect_only.drop(columns = [x for x in df_sect_only.columns if x == 'outcome' or x == 'sample_id'])\n",
    "norm_ex = normalize(ex)\n",
    "scale_ex = std_scl.fit_transform(ex)\n",
    "\n",
    "why = df_sect_only.drop(columns = [x for x in df_sect_only.columns if x != 'outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sect_only['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10X ITERATED 3-FOLD CROSS-VALIDATED ACCURACY AND PRECISION FOR MOST ROBUST EVAL W/SMALL SAMPLE\n",
    "rkf = RepeatedKFold(n_splits=3, n_repeats=10)\n",
    "log = lm.LogisticRegression()\n",
    "acc_scores = cross_val_score(log, scale_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(log, scale_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW RANDOM FOREST\n",
    "rf = ens.RandomForestClassifier()\n",
    "acc_scores = cross_val_score(rf, ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(rf, ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = lm.LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "acc_scores = cross_val_score(lasso, scale_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(lasso, scale_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in np.arange(1, 102, 10):\n",
    "    rdg = lm.RidgeClassifier(alpha = a)\n",
    "    acc_scores = cross_val_score(rdg, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(rdg, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(a, ' ridge accuracy: ', np.mean(acc_scores))\n",
    "    print(a, ' ridge precision: ', np.mean(prec_scores))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kern in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    \n",
    "    svc = SVC(kernel = kern, probability = True)\n",
    "    \n",
    "    acc_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(kern, ' accuracy: ', np.mean(acc_scores))\n",
    "    print(kern, ' precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRYING WAYYYYY SLIMMED DOWN VERSION\n",
    "df_trim = df_all_updated.copy()\n",
    "df_trim = df_trim.drop(columns = [x for x in df_trim.columns if 'gene_'  in x or\\\n",
    "                                             'med_' in x or 'nty' in x or\\\n",
    "                                              ('rawscore' in x and 'non_neg' not in x) or\\\n",
    "                                 ('section' in x and\\\n",
    "                                  'chrom_11' not in x and\\\n",
    "                                  'chrom_1' not in x and\\\n",
    "                                  'chrom_16' not in x and \\\n",
    "                                  'chrom_6' not in x and \\\n",
    "                                  'chrom_17' not in x and \\\n",
    "                                  'chrom_2' not in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trim.to_csv(\"trim_stats_by_sample.csv\")\n",
    "df_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = df_trim.drop(columns = [x for x in df_trim.columns if x == 'outcome' or x == 'sample_id'])\n",
    "norm_ex = normalize(ex)\n",
    "scale_ex = std_scl.fit_transform(ex)\n",
    "\n",
    "why = df_trim.drop(columns = [x for x in df_trim.columns if x != 'outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trim['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10X ITERATED 3-FOLD CROSS-VALIDATED ACCURACY AND PRECISION FOR MOST ROBUST EVAL W/SMALL SAMPLE\n",
    "rkf = RepeatedKFold(n_splits=3, n_repeats=10)\n",
    "log = lm.LogisticRegression()\n",
    "acc_scores = cross_val_score(log, scale_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(log, scale_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW RANDOM FOREST\n",
    "rf = ens.RandomForestClassifier()\n",
    "acc_scores = cross_val_score(rf, ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(rf, ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = lm.LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "acc_scores = cross_val_score(lasso, scale_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(lasso, scale_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in np.arange(1, 102, 10):\n",
    "    rdg = lm.RidgeClassifier(alpha = a)\n",
    "    acc_scores = cross_val_score(rdg, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(rdg, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(a, ' ridge accuracy: ', np.mean(acc_scores))\n",
    "    print(a, ' ridge precision: ', np.mean(prec_scores))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kern in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    \n",
    "    svc = SVC(kernel = kern, probability = True)\n",
    "    \n",
    "    acc_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(kern, ' accuracy: ', np.mean(acc_scores))\n",
    "    print(kern, ' precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRYING NOT EVEN SECTION\n",
    "df_v_trim = df_all.copy()\n",
    "df_v_trim = df_trim.drop(columns = [x for x in df_trim.columns if 'gene_'  in x or\\\n",
    "                                             'med_' in x or 'nty' in x or\\\n",
    "                                              ('rawscore' in x and 'non_neg' not in x) or\\\n",
    "                                   'section' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = df_v_trim.drop(columns = [x for x in df_v_trim.columns if x == 'outcome' or x == 'sample_id'])\n",
    "norm_ex = normalize(ex)\n",
    "scale_ex = std_scl.fit_transform(ex)\n",
    "\n",
    "why = df_v_trim.drop(columns = [x for x in df_v_trim.columns if x != 'outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v_trim['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10X ITERATED 3-FOLD CROSS-VALIDATED ACCURACY AND PRECISION FOR MOST ROBUST EVAL W/SMALL SAMPLE\n",
    "rkf = RepeatedKFold(n_splits=3, n_repeats=10)\n",
    "log = lm.LogisticRegression()\n",
    "acc_scores = cross_val_score(log, scale_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(log, scale_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW RANDOM FOREST\n",
    "rf = ens.RandomForestClassifier()\n",
    "acc_scores = cross_val_score(rf, ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(rf, ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = lm.LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "acc_scores = cross_val_score(lasso, scale_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "prec_scores = cross_val_score(lasso, scale_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "print('accuracy: ', np.mean(acc_scores))\n",
    "print('precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in np.arange(1, 102, 10):\n",
    "    rdg = lm.RidgeClassifier(alpha = a)\n",
    "    acc_scores = cross_val_score(rdg, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(rdg, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(a, ' ridge accuracy: ', np.mean(acc_scores))\n",
    "    print(a, ' ridge precision: ', np.mean(prec_scores))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kern in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    \n",
    "    svc = SVC(kernel = kern, probability = True)\n",
    "    \n",
    "    acc_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='accuracy', cv=rkf, n_jobs=-1)\n",
    "    prec_scores = cross_val_score(svc, norm_ex, why.values.ravel(), scoring='precision', cv=rkf, n_jobs=-1)\n",
    "    print(kern, ' accuracy: ', np.mean(acc_scores))\n",
    "    print(kern, ' precision: ', np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF W/NO SECTION CONSISTENTLY BEST\n",
    "# NEED TO FIGURE OUT SOME VERSION OF FEATURE SELECTION THAT DOESN'T RULE OUT CROSS VAL\n",
    "# FOR NOW, GOING TO COMPARE 10K ITERATED FI VS PLAIN FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = df_sect_only.drop(columns = [x for x in df_all.columns if x == 'outcome' or x == 'sample_id'])\n",
    "norm_ex = normalize(ex)\n",
    "scale_ex = std_scl.fit_transform(ex)\n",
    "\n",
    "why = df_all.drop(columns = [x for x in df_all.columns if x != 'outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ex = df_sect_only.drop(columns = [x for x in df_sect_only.columns if x == 'outcome' or x == 'sample_id'])\n",
    "norm_ex = normalize(ex)\n",
    "scale_ex = std_scl.fit_transform(ex)\n",
    "\n",
    "why = df_sect_only.drop(columns = [x for x in df_sect_only.columns if x != 'outcome'])\n",
    "final_df = pd.DataFrame()\n",
    "for i in range(10000):\n",
    "    print(i)\n",
    "    ex_train, ex_test, why_train, why_test = train_test_split(ex, why, test_size = .25)\n",
    "\n",
    "    ada = ens.AdaBoostClassifier().fit(ex_train, why_train.values.ravel())\n",
    "#     rf = ens.RandomForestClassifier().fit(ex_train, why_train.values.ravel())\n",
    "    \n",
    "    feature_names = [x for x in df_sect_only.columns if x != 'outcome' and x != 'sample_id']\n",
    "#     importances = rf.feature_importances_\n",
    "    importances = ada.feature_importances_\n",
    "    data = {'feature_names': feature_names, 'feature_importance': importances}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    final_df = pd.concat([final_df, fi_df])\n",
    "final_df.to_csv(\"ada_fi.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_df = final_df.copy()\n",
    "\n",
    "keep_df = keep_df.groupby('feature_names').sum().reset_index()\n",
    "keep_df.sort_values(by = ['feature_importance'], ascending = False, inplace = True)\n",
    "keep_df = keep_df.head(25)\n",
    "\n",
    "# keep_df = keep_df[keep_df['feature_importance'] >= 23]\n",
    "\n",
    "keep_df.to_csv(\"ada_fi.csv\")\n",
    "\n",
    "# keep_df = keep_df.head(25)\n",
    "\n",
    "# keep_df.to_csv(\"rf_fi_df_all_top_25.csv\")\n",
    "\n",
    "#DEFINE SIZE OF BAR PLOT\n",
    "# keep_df = pd.read_csv(\"ada_fi.csv\")\n",
    "# keep_df = keep_df.head(25)\n",
    "# keep_df.to_csv(\"ada_fi.csv\")\n",
    "plt.figure(figsize = (5, 7))\n",
    "keep_df['feature_importance'] /= 10000\n",
    "keep_df['type'] = keep_df['feature_names'].apply(lambda x: 'CADD Score' if 'non_neg_rawscore' in x else \\\n",
    "                                                 ('Number of Mutations' if 'mutations' in x else 'Clinical'))\n",
    "\n",
    "keep_df['feature_names'] = keep_df['feature_names'].apply(lambda x: re.sub('chrom', 'Chrom.', \n",
    "                                                            re.sub('chromosome', 'Chromosome', \n",
    "                                                            re.sub('section', 'Mbp', \n",
    "                                                            re.sub('_', ' ',\n",
    "                                                            re.sub('_mutations', '', \n",
    "                                                            re.sub('_non_neg_rawscore', '', x)))))))\n",
    "\n",
    "#PLOT SEABORN BAR CHART\n",
    "sns.barplot(x = keep_df['feature_importance'], y = keep_df['feature_names'], hue = keep_df['type'], ci = None)\n",
    "\n",
    "#ADD CHART LABELS\n",
    "plt.title('Adaboost Feature Importance')\n",
    "plt.legend(title = \"Variable Type\")\n",
    "plt.xlabel('Average Feature Importance (10k Iterations)')\n",
    "plt.ylabel('Feature Names')\n",
    "plt.savefig(\"adaboost_fi\", bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
