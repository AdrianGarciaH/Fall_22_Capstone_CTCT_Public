{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSSrN8TMNlf6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn import metrics, feature_extraction, feature_selection, model_selection, pipeline, manifold, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "import torch\n",
    "\n",
    "## for bert language model\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQTQ16ltN1mn"
   },
   "outputs": [],
   "source": [
    "### Load data\n",
    "df = pd.read_csv('nlp_all_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "CS7otD9vOhv1",
    "outputId": "49880ea6-4955-4855-ee3d-4caed7d08b79"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYhc8ZG0Oigb"
   },
   "outputs": [],
   "source": [
    "### Split data into train and test set, stratified on our target\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['note_text'], df['target'],\n",
    "                                   random_state=123, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True,\n",
    "                                   stratify = df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUPeciKROn-T",
    "outputId": "eb3d93a4-c016-49cb-899c-cd6d81a4272c"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9FLUcmCPTnk",
    "outputId": "731c5343-af94-444b-e15d-f8913bf23aa2"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCu_mutkStUY",
    "outputId": "8e7fc71f-17e7-434b-94a2-f39ead0b539f"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBzyhWw9PkIc"
   },
   "source": [
    "### Getting bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ejqyw9TsPV2d",
    "outputId": "2a717b78-f167-40f3-8306-0f313fa5eac8"
   },
   "outputs": [],
   "source": [
    "# I'll be using the embeddings from the bert base uncasedmodel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R020ljEoPsRT",
    "outputId": "4adf0927-0eaf-45d0-d493-e39b3b59cfe7"
   },
   "outputs": [],
   "source": [
    "# We will start by gathering the embeddings for the test set\n",
    "cls_val_list = []\n",
    "batch_size = 1000\n",
    "\n",
    "for batch_number, batch_test in X_test.groupby(np.arange(len(X_test)) // batch_size):\n",
    "    # tokanizing the text\n",
    "    tokenized_val = tokenizer(batch_test.values.tolist() , padding = 'max_length', truncation = True,  return_tensors=\"pt\", max_length=256)\n",
    "\n",
    "    # move on device (GPU)\n",
    "    tokenized_val = {k:torch.tensor(v).to(device) for k,v in tokenized_val.items()}\n",
    "\n",
    "    # get the cls hidden state\n",
    "    with torch.no_grad():\n",
    "        hidden_val = model(**tokenized_val)\n",
    "            \n",
    "    #get only the [CLS] hidden states\n",
    "    cls_val = hidden_val.last_hidden_state[:,0,:]\n",
    "    cls_val = cls_val.to(\"cpu\")\n",
    "    cls_val_list.append(cls_val)\n",
    "    del cls_val\n",
    "    del hidden_val\n",
    "    del tokenized_val\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cls_val_list_final = []\n",
    "for i in range(len(cls_val_list)):\n",
    "    for j in range(len(cls_val_list[i])):\n",
    "        cls_val_list_final.append(cls_val_list[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avzFbXNJQNqA",
    "outputId": "3ed8ddd1-3015-4e07-d526-9b40b880d55f"
   },
   "outputs": [],
   "source": [
    "# Get embeddigns for the training set\n",
    "cls_train_list = []\n",
    "batch_size = 1000\n",
    "\n",
    "for batch_number, batch_train in X_train.groupby(np.arange(len(X_train)) // batch_size):\n",
    "    # tokanizing the text\n",
    "    tokenized_train = tokenizer(batch_train.values.tolist() , padding = 'max_length', truncation = True,  return_tensors=\"pt\", max_length=256)\n",
    "\n",
    "    # move on device (GPU)\n",
    "    tokenized_train = {k:torch.tensor(v).to(device) for k,v in tokenized_train.items()}\n",
    "\n",
    "    # get the cls hidden state\n",
    "    with torch.no_grad():\n",
    "        hidden_train = model(**tokenized_train)\n",
    "            \n",
    "    #get only the [CLS] hidden states\n",
    "    cls_train = hidden_train.last_hidden_state[:,0,:]\n",
    "    cls_train = cls_train.to(\"cpu\")\n",
    "    cls_train_list.append(cls_train)\n",
    "    del cls_train\n",
    "    del hidden_train\n",
    "    del tokenized_train\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cls_train_list_final = []\n",
    "for i in range(len(cls_train_list)):\n",
    "    for j in range(len(cls_train_list[i])):\n",
    "        cls_train_list_final.append(cls_train_list[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCj6-NVkQl_d"
   },
   "outputs": [],
   "source": [
    "# Move the output embeddigns for the trainign and validation sets into a dataframe\n",
    "X_train = torch.stack(cls_train_list_final)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "X_test = torch.stack(cls_val_list_final)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "6vWIRV2bRZCY",
    "outputId": "e9ab4d14-6a72-4cb7-9f8e-8a3ee359650a"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMEm2Fw9SLsz"
   },
   "source": [
    "## Training classifiers on our embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mi6L_JheSP_T"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "4Ov6FJ-cSOfw",
    "outputId": "3f61f4cd-3df0-4a54-99af-7dfb9ad9610e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log =LogisticRegression(random_state=0, max_iter= 300)\n",
    "\n",
    "## train classifier\n",
    "log.fit(X_train, y_train)\n",
    "## test\n",
    "predicted = log.predict(X_test)\n",
    "predicted_prob = log.predict_proba(X_test)\n",
    "\n",
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEp3NjvzT84m"
   },
   "source": [
    "#### Random Forest Classsifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "id": "0HrK6e2GSixa",
    "outputId": "b987be0c-d162-4e22-b367-84e5ab91b962"
   },
   "outputs": [],
   "source": [
    "#### Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=150, n_estimators=30, max_features=768)\n",
    "\n",
    "## train classifier\n",
    "forest.fit(X_train, y_train)\n",
    "## test\n",
    "predicted = forest.predict(X_test)\n",
    "predicted_prob = forest.predict_proba(X_test)\n",
    "\n",
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIGWQ9wRVYvK"
   },
   "source": [
    "#### K-neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "id": "Yfebqy8DVcgb",
    "outputId": "40f704f3-21a9-479f-85c9-eb717da550bb"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "## train classifier\n",
    "neigh.fit(X_train, y_train)\n",
    "## test\n",
    "predicted = neigh.predict(X_test)\n",
    "predicted_prob = neigh.predict_proba(X_test)\n",
    "\n",
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NddgqXBuV5DM"
   },
   "source": [
    "#### ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "id": "_tkutGdLV6VD",
    "outputId": "d299d231-aaff-42b9-8116-cf3009f76d90"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "## train classifier\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "## test\n",
    "predicted = ada.predict(X_test)\n",
    "predicted_prob = ada.predict_proba(X_test)\n",
    "\n",
    "# lets see our model performance\n",
    "classes = np.unique(y_test)\n",
    "y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "## Accuracy, Precision, Recall\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "\n",
    "print(\"Accuracy:\",  round(accuracy,2))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  \n",
    "                           predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "              label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
