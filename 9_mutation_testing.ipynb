{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model as lm, metrics, ensemble as ens\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE, RFECV, SequentialFeatureSelector\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "# from collections import defaultdict\n",
    "# from itertools import islice\n",
    "# from scipy.stats import permutation_test\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.genmod.generalized_linear_model import GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING A FUNCTION TO UPDATE COLUMN NAMES LATER\n",
    "def lower_no_space(word): \n",
    "    \n",
    "    word = re.sub(' ', '_', word) \n",
    "    \n",
    "    word = re.sub(r'\\'', '', word) \n",
    "    \n",
    "    word = re.sub(r'\\(', '', word)\n",
    "    \n",
    "    word = re.sub(r'\\)', '', word)\n",
    "    \n",
    "    word = re.sub('\\?', '', word)\n",
    "    \n",
    "    word = re.sub('/', '_', word)\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.read_csv(\"full_gen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ IN Updated CLINICAL DATA FOR LATER USE (CONVERTED TO .csv IN GOOGLE SHEETS)\n",
    "df_clin_updated = pd.read_csv(\"Homebase_new_updated.csv\", header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAMING COLUMNS\n",
    "df_clin_updated = df_clin_updated.rename(mapper = lower_no_space, axis = 1) \n",
    "df_clin_updated.rename(columns={'subject_sample_id':'sample_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the age at initial diagnosis from date of birth and date_of_initial_diagnosis\n",
    "df_clin_updated['date_of_birth'] = pd.to_datetime(df_clin_updated['date_of_birth'])\n",
    "df_clin_updated['date_of_initial_diagnosis'] = pd.to_datetime(df_clin_updated['date_of_initial_diagnosis'])\n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = (pd.DatetimeIndex(df_clin_updated['date_of_initial_diagnosis']).year \n",
    "                        - pd.DatetimeIndex(df_clin_updated['date_of_birth']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the abnormal in date of birth from the Stanford data, \n",
    "#Remove the age at initial diagonosis for data from Stanford & the one that has negative age \n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = np.where(df_clin_updated['data_access_group'] == 'Stanford', np.nan, df_clin_updated[\"age_at_initial_diagnosis\"])\n",
    "df_clin_updated[\"age_at_initial_diagnosis\"] = np.where(df_clin_updated[\"age_at_initial_diagnosis\"] < 0, np.nan, df_clin_updated[\"age_at_initial_diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data type: date_of_birth, n, m \n",
    "df_clin_updated = df_clin_updated.astype({'t':'object', 'b':'object'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TONS OF DATA, PULL WHAT WE WANT\n",
    "df_clin_updated_lean = df_clin_updated.drop(columns = [x for x in df_clin_updated.columns if x not in ['gender', 'race', \\\n",
    "                                       'country_of_residence', 'sample_id', 'ethnicity',\\\n",
    "                                        'age_at_initial_diagnosis', 't', 'n', 'm', 'b',\\\n",
    "                                        'predominant_lesion_type_at_diagnosis','lymph_node_biopsy_performed',\\\n",
    "                                        'family_history_of_leukemia_lymphoma', \\\n",
    "                                        'has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical',\\\n",
    "                                        'cd4+:cd8+_ratio', 'total_lymphocyte_count', 'absolute_cd4+_count_per_ul',\\\n",
    "                                        '%cd4+cd26-', '%cd4+cd7-', 'tcr_clonality', 'tumor_cell_cd30+',\\\n",
    "                                        'large_cell_transformation', 'ldh_u_l', 'wbc_103_μl', 'rbc_106_μl',\\\n",
    "                                        'hematocrit_%', 'mcv_fl', 'mchc_g_dl', 'rdw_%', 'platelet_count_103_μl',\\\n",
    "                                        'segmented_neutrophil,_absolute_103_μl', 'lymphocyte,_absolute_103_μl',\\\n",
    "                                        'monocytes,_absolute_103_μl', 'eosinophils,_absolute_103_μl',\\\n",
    "                                        'basophils,_absolute_103_μl', 'segmented_neutrophils_%', 'lymphocytes_%',\\\n",
    "                                        'monocytes_%', 'eosinophils_%', 'basophils_%']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN YES/NO & POSITIVE/NEGATIVE TO DUMMIES\n",
    "df_clin_updated_lean['lymph_node_biopsy_performed'] = \\\n",
    "df_clin_updated_lean['lymph_node_biopsy_performed'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['family_history_of_leukemia_lymphoma'] = \\\n",
    "df_clin_updated_lean['family_history_of_leukemia_lymphoma'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['tumor_cell_cd30+'] = \\\n",
    "df_clin_updated_lean['tumor_cell_cd30+'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['large_cell_transformation'] = \\\n",
    "df_clin_updated_lean['large_cell_transformation'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "df_clin_updated_lean['tcr_clonality'] = \\\n",
    "df_clin_updated_lean['tcr_clonality'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "df_clin_updated_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'] = \\\n",
    "df_clin_updated_lean['has_the_patient_ever_been_exposed_at_work_or_in_the_service_to_a_toxic_chemical'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Preprocessed Genetic Data\n",
    "df_lean = pd.read_csv ('stats_by_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM SAMPLE ID TO JOIN TO CLINICAL DATA\n",
    "df_lean['sample_id'] = df_lean['sample_id'].apply(lambda x: re.sub('_', '-', x[:5]) if 'WES' in x else\\\n",
    "                                                  (x[:-10] if 'CTCL' in x else \\\n",
    "                                                  (x[:-13] if 'almeida' in x else\\\n",
    "                                                  ((x[-2:]+x[:-2])[:-15] if 'ungewickell' in x else\\\n",
    "                                                  ('-'.join([ele.lstrip('0').lower() for ele in x[:-10].split('-')]) if 'SPZ' in x else x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE tbe updated CLINICAL, GENETIC DATA\n",
    "df_all_updated = pd.merge(df_lean, df_clin_updated_lean, on='sample_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPUTATION; \"UNKNOWN\" FOR CATEGORICAL, MEAN FILL-IN FOR CONTINUOUS\n",
    "for col in df_clin_updated_lean.columns:\n",
    "    if col in ['race', 'gender', 'country_of_residence', 'ethnicity', 'predominant_lesion_type_at_diagnosis', 't', \n",
    "              'n', 'm', 'b']:\n",
    "        df_all_updated[col] = df_all_updated[col].fillna('unknown')\n",
    "    elif col != 'sample_id':\n",
    "        df_all_updated[col] = df_all_updated[col].fillna(np.mean(df_all_updated[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DUMMIES FOR CATEGORICALS\n",
    "df_all_updated = pd.get_dummies(df_all_updated, columns = ['race', 'gender', 'country_of_residence', 'ethnicity', 'predominant_lesion_type_at_diagnosis', \n",
    "                                                          't', 'n', 'm', 'b'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE STANDARDSCALER FOR LATER USE\n",
    "std_scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define (Scaled/Normalized) Features and Labels\n",
    "X_new = df_all_updated.drop(columns = [x for x in df_all_updated.columns if x == 'outcome' or x == 'sample_id'])\n",
    "X_new_scaled = std_scl.fit_transform(X_new)\n",
    "X_new_norm = normalize(X_new)\n",
    "\n",
    "y_new = df_all_updated.drop(columns = [x for x in df_all_updated.columns if x != 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_updated['outcome'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CHROMOSOMES OF INTEREST\n",
    "top_feats = pd.read_csv(\"ada_fi.csv\").head(25).drop(columns = ['Unnamed: 0'])\n",
    "top_feats\n",
    "chroms_to_use = top_feats[top_feats['feature_names'].str.contains(\"chromosome\")]['feature_names']\n",
    "chroms_to_use = [re.sub('chromosome_', '', \\\n",
    "                        re.sub('_mutations', '', \\\n",
    "                               re.sub('_rawscore', '', \\\n",
    "                                      re.sub('_non_neg_rawscore', '', \\\n",
    "                                             re.sub('med_', '', x))))) \\\n",
    "                 for x in chroms_to_use]\n",
    "\n",
    "\n",
    "chroms_to_use_2 = top_feats[(top_feats['feature_names'].str.contains(\"section\")) &\\\n",
    "                           ~(top_feats['feature_names'].str.contains(\"chromosome\"))]['feature_names']\n",
    "chroms_to_use_2 = [re.sub('_mutations', '', \\\n",
    "                          re.sub('_rawscore', '', \\\n",
    "                                 re.sub('_non_neg_rawscore', '', \\\n",
    "                                        x.split(\"chrom_\", 1)[1])))\\\n",
    "                  for x in chroms_to_use_2]\n",
    "\n",
    "\n",
    "chroms_to_use += chroms_to_use_2\n",
    "chroms_to_use = list(set(chroms_to_use))\n",
    "chroms_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = df_all_updated.copy()\n",
    "cols_to_use = ['outcome']\n",
    "\n",
    "for gene in set(df_gen[df_gen['chrom'].isin(chroms_to_use)]['gene_symbol']):\n",
    "    if ('gene_' + gene + '_non_neg_rawscore') in df_lean.columns:\n",
    "            cols_to_use.append('gene_' + gene + '_non_neg_rawscore')\n",
    "df_use = df_use.drop(columns = [x for x in df_use.columns if x not in cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = lm.LogisticRegression()\n",
    "rf = ens.RandomForestClassifier()\n",
    "rdg = lm.RidgeClassifier(alpha = 1)\n",
    "ada = ens.AdaBoostClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT FEW CELLS ARE ABOUT GETTING P-VALS FROM SKLEARN;\n",
    "METHODOLOGY LEARNED HERE:\n",
    "https://stackoverflow.com/questions/27928275/find-p-value-significance-in-scikit-learn-linearregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_use.drop(columns = [x for x in df_use.columns if x == 'sample_id' or x == 'outcome'])\n",
    "y = df_use['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perm_test():\n",
    "    def linear(self, model_type, ex, why):\n",
    "        \n",
    "        model = model_type.fit(ex, why.values.ravel())\n",
    "        \n",
    "        # DEFINE FULL MODEL PARAMS (INCLUDE B_0) AND PREDICTIONS YOU WOULD GET\n",
    "        params = np.append(model.intercept_, model.coef_)\n",
    "        predictions = model.predict(ex)\n",
    "        \n",
    "        # MAKE NEW DF TO STORE KEY VALUES, DEFINE MSE OF PREDS FROM PREV CELL\n",
    "        newX = pd.DataFrame({\"Constant\":np.ones(len(ex))}).join(pd.DataFrame(ex))\n",
    "        \n",
    "        # DEFINE VAR, SD, T SCORE\n",
    "        # DIAGONAL OF COVARIANCE MATRIX SHOULD EQUAL AN ARRAY OF ALL COEF VAR\n",
    "        var_b = newX.cov().to_numpy().diagonal().copy()\n",
    "        var_b += .0000000001 #ADDING VERY SMALL NUMBER TO DEAL WITH 0s\n",
    "        sd_b = np.sqrt(var_b)\n",
    "        ts_b = params/ sd_b #T STATISTIC = (ESTIMATED COEF - HYPOTHESIZED COEF (0))/COEF SAMPLE STANDARD ERROR\n",
    "        \n",
    "        p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX) - 1))) for i in ts_b]\n",
    "        p_values = np.round(p_values,3)\n",
    "        \n",
    "        genes_comp = {}\n",
    "\n",
    "        for i in range(len(ex.columns)):\n",
    "            gene = re.sub('gene_', '', re.sub('_non_neg_rawscore', '', ex.columns[i]))\n",
    "            genes_comp[gene] = {}\n",
    "            genes_comp[gene]['p_val'] = p_values[i + 1]\n",
    "            \n",
    "        random_best_p_values = []\n",
    "\n",
    "        for i in range(10000):\n",
    "            print(i)            \n",
    "            temp_df = df_use.copy() #DON'T ALTER ORIG DF\n",
    "\n",
    "            # GET CORRECTLY SIZED GROUPS, RANDOMLY ASSIGNED, SAME SPLITS AS IN ORIG\n",
    "            ss_sized_group = temp_df.sample(n = len(set(df_gen[df_gen['outcome'] == 1]['sample_id'])))\n",
    "            mf_sized_group = temp_df[~temp_df.index.isin(ss_sized_group.index.values)]\n",
    "\n",
    "        #     RESET OUTCOME VALS BASED ON GROUP (NOW OUTCOME IS RANDOM)\n",
    "            ss_sized_group['outcome'].values[:] = 1\n",
    "            mf_sized_group['outcome'].values[:] = 0\n",
    "\n",
    "        #     RECOMBINE INTO ONE DF\n",
    "            new_df = pd.concat([ss_sized_group, mf_sized_group])\n",
    "    \n",
    "                # DEFINE X, Y, FITTED MODEL\n",
    "            X = new_df.drop(columns = [x for x in new_df.columns if x == 'sample_id' or x == 'outcome'])\n",
    "            y = new_df['outcome']\n",
    "            \n",
    "            model = model_type.fit(ex, why)\n",
    "            \n",
    "            params = np.append(model.intercept_, model.coef_)\n",
    "            predictions = model.predict(ex)\n",
    "            \n",
    "            newX = pd.DataFrame({\"Constant\":np.ones(len(ex))}).join(pd.DataFrame(ex))\n",
    "            \n",
    "            var_b = newX.cov().to_numpy().diagonal().copy()\n",
    "            var_b += .000000001\n",
    "            sd_b = np.sqrt(var_b)\n",
    "            ts_b = params/ sd_b\n",
    "    \n",
    "            p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX) - 1))) for i in ts_b]\n",
    "            p_values = np.round(p_values,3)\n",
    "            p_values = p_values[1:] #FIRST ONE WILL BE FOR CONSTANT (SHOULD EQUAL 0)\n",
    "    \n",
    "            baseline = np.min(p_values)\n",
    "            random_best_p_values.append(baseline)\n",
    "            \n",
    "        for i in range(len(ex.columns)):\n",
    "            gene = re.sub('gene_', '', re.sub('_non_neg_rawscore', '', ex.columns[i]))\n",
    "\n",
    "            genes_comp[gene]['p_val'] = len([x for x in random_best_p_values if x < genes_comp[gene]['p_val']])/10000\n",
    "    \n",
    "        genes_comp_ordered = {k: v for k, v in sorted(genes_comp.items(), key=lambda item: item[1]['p_val'], reverse = False)}\n",
    "        return genes_comp_ordered\n",
    "    \n",
    "\n",
    "            \n",
    "    def tree_based(self, model_type, ex, why):\n",
    "        \n",
    "        model = model_type.fit(ex, why.values.ravel())\n",
    "        \n",
    "        genes_comp = {}\n",
    "\n",
    "        for i in range(len(ex.columns)):\n",
    "            gene = re.sub('gene_', '', re.sub('_non_neg_rawscore', '', ex.columns[i]))\n",
    "            genes_comp[gene] = {}\n",
    "            genes_comp[gene]['fi'] = model.feature_importances_[i]\n",
    "            \n",
    "        random_best_fi_vals = []\n",
    "\n",
    "        for i in range(10000):\n",
    "            print(i)            \n",
    "            temp_df = df_use.copy() #DON'T ALTER ORIG DF\n",
    "\n",
    "            ss_sized_group = temp_df.sample(n = len(set(df_gen[df_gen['outcome'] == 1]['sample_id'])))\n",
    "            mf_sized_group = temp_df[~temp_df.index.isin(ss_sized_group.index.values)]\n",
    "\n",
    "            ss_sized_group['outcome'].values[:] = 1\n",
    "            mf_sized_group['outcome'].values[:] = 0\n",
    "\n",
    "            new_df = pd.concat([ss_sized_group, mf_sized_group])\n",
    "\n",
    "            X = new_df.drop(columns = [x for x in new_df.columns if x == 'sample_id' or x == 'outcome'])\n",
    "            y = new_df['outcome']\n",
    "            model = model_type.fit(ex, why)\n",
    "            \n",
    "            baseline = np.max(model.feature_importances_)\n",
    "            random_best_fi_vals.append(baseline)\n",
    "            \n",
    "        for i in range(len(ex.columns)):\n",
    "            gene = re.sub('gene_', '', re.sub('_non_neg_rawscore', '', ex.columns[i]))\n",
    "\n",
    "            genes_comp[gene]['p_val'] = len([x for x in random_best_fi_vals if x > genes_comp[gene]['fi']])/10000\n",
    "    \n",
    "        genes_comp_filtered = {}\n",
    "\n",
    "        for (key, value) in genes_comp.items():\n",
    "           # Check if key is even then add pair to new dictionary\n",
    "           if value['fi'] != 0:\n",
    "               genes_comp_filtered[key] = value\n",
    "            \n",
    "        genes_comp_ordered = {k: v for k, v in sorted(genes_comp_filtered.items(), key=lambda item: item[1]['p_val'], reverse = False)}\n",
    "        return genes_comp_ordered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOGISTIC REGRESSION \\n\")\n",
    "log_perm = perm_test()\n",
    "log_perm_result = log_perm.linear(log, X, y)\n",
    "print(\"RIDGE CLASSIFIER \\n\")\n",
    "rdg_perm = perm_test()\n",
    "rdg_perm_result = rdg_perm.linear(rdg, X, y)\n",
    "print(\"ADABOOST \\n\")\n",
    "ada_perm = perm_test()\n",
    "ada_perm_result = ada_perm.tree_based(ada, X, y)\n",
    "print(\"RANDOM FOREST \\n\")\n",
    "rf_perm = perm_test()\n",
    "rf_perm_result = rf_perm.tree_based(rf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_df = pd.DataFrame.from_dict(ada_perm_result)\n",
    "ada_df.to_csv(\"ada_dict.csv\")\n",
    "rf_df = pd.DataFrame.from_dict(rf_perm_result)\n",
    "rf_df.to_csv(\"rf_dict.csv\")\n",
    "rdg_df = pd.DataFrame.from_dict(rdg_perm_result)\n",
    "rdg_df.to_csv(\"rdg_dict.csv\")\n",
    "log_df = pd.DataFrame.from_dict(log_perm_result)\n",
    "log_df.to_csv(\"log_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_perm_result\n",
    "# ADABOOST - IQSEC1: FI = .1, P-VAL = .0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_perm_result\n",
    "# RANDOM FOREST - NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_perm_result\n",
    "# LOGISTIC REGRESSION - KRTAP5-5: P-VAL = 0; TPSD1: P-VAL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_perm_result\n",
    "# RIDGE CLASSIFIER - KRTAP5-5: P-VAL = 0; TPSD1: P-VAL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
