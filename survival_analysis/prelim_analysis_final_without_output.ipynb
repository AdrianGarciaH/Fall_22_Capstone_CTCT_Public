{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scikit_posthocs as sp\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_redcap_data = 'Homebase_new_updated.csv'\n",
    "file_header_mappings = 'ClinicalGenomicCorre_header_mappings.xlsx'\n",
    "file_genetics_data = '1-s2.0-S0022202X18322942-mmc2_MAIN GENOMIC.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read REDCap data export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_header = pd.read_excel(file_header_mappings)\n",
    "header_labels = df_header.loc[0, :].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_redcap_data, index_col=0, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Age at CBC prior to sampling (can answer instead of 'date of CBC prior to sampling')\",\n",
    " 'Age at Initial Diagnosis - can answer instead of Date of Initial Diagnosis  ',\n",
    " \"Age at LDH collection (prior to sampling) - can answer instead of 'Date of LDH collection prior to sampling'\",\n",
    " \"Age at date of relapse/disease progression 1 (can answer instead of 'date of relapse/disease progression 1')\",\n",
    " \"Age at date of relapse/disease progression 2 (can answer instead of 'date of relapse/disease progression 2')\",\n",
    " \"Age at date of relapse/disease progression 3 (can answer instead of 'date of relapse/disease progression 3')\",\n",
    " \"Age at date of relapse/disease progression 4 (can answer instead of 'date of relapse/disease progression 4')\",\n",
    " \"Age at date of relapse/disease progression 5 (can answer instead of 'date of relapse/disease progression 5')\",\n",
    " \"Age at death (can answer instead of 'date of death')\",\n",
    " \"Age at large cell transformation (can answer instead of 'date of large cell transformation')\",\n",
    " \"Age at sampling used for genetic analysis (can answer instead of 'date of sampling for genetic analysis')\",\n",
    " \"Age during CBC with differential at time of sampling (can answer instead of 'date of CBC with differential at time of sampling')\",\n",
    " 'Current Age (At Time of Data Entry) - can answer instead of DOB'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap out the column names (non-distinct labels) with the distinct REDCap variable names \n",
    "df.columns = list(header_labels.keys())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop rows where the subject_id is empty\n",
    "df = df.dropna(axis=0, subset=['subject_id'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map IDs to genomics file\n",
    "\n",
    "Subject ID entries in REDCap do not exactly match those in the genomics data file, and each group seems to enter their IDs a little differently. This function tries to figure out these differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_id_to_sample_id(x):\n",
    "    if type(x) is not str:\n",
    "        return ''\n",
    "    \n",
    "    # Wang (MD Anderson): SPZ-###__wang__SS\n",
    "    # note: in REDCap, sometimes entered as \"spz-#\" or \"spz #\"\n",
    "    r = re.compile('^spz[ -](\\d{1,2})$')\n",
    "    m = r.match(x)\n",
    "    if m is not None:\n",
    "        return f'SPZ-{int(m[1]):03d}__wang__SS'\n",
    "    \n",
    "    # Choi (Yale): CTCL# --> CTCL#__choi__SS\n",
    "    r = re.compile('^CTCL(\\d{1,2})$')\n",
    "    m = r.match(x)\n",
    "    if m is not None:\n",
    "        return f'CTCL{m[1]}__choi__SS'\n",
    "    \n",
    "    # Woollard (Kings College): WES-# --> WES_#__woolard__SS\n",
    "    r = re.compile('^WES-(\\d{1,2})$')\n",
    "    m = r.match(x)\n",
    "    if m is not None:\n",
    "        return f'WES_{m[1]}__woollard__SS'\n",
    "    \n",
    "    # Almeida (Leiden): SS_L# --> SS_L#__almeida__SS\n",
    "    # note: Almeida also has another format for SS_NU#__almedeida__SS that so far is not observed in REDCap\n",
    "    r = re.compile('^SS_([NU|L]\\d{1,2})$')\n",
    "    m = r.match(x)\n",
    "    if m is not None:\n",
    "        return f'SS_{m[1]}__almeida__SS'\n",
    "    \n",
    "    # Prasad (Barcelona): SS##__prasad__SS --> SS##__prasad__SS \n",
    "    # note: subject ID in REDCap matches sample_id in genomics file exactly\n",
    "    r = re.compile('^SS\\d{2}__prasad__SS$')\n",
    "    m = r.match(x)\n",
    "    if m is not None:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    return ''\n",
    "    \n",
    "    \n",
    "df['sample_id'] = df.subject_id.apply(subject_id_to_sample_id)\n",
    "df[['subject_id', 'sample_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_first = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows and columns with high missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop participants that are mostly empty\n",
    "\n",
    "# axis = 0: along the rows (going down)\n",
    "# axis = 1: along the columns (going right)\n",
    "x = df.isnull().sum(axis=1)\n",
    "x.hist()\n",
    "df = df[x<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = [item for item in copy_df_first.index.to_list() if item not in df.index.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200/341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(copy_df_first.loc[missing, :].index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_first.loc[missing, 'redcap_data_access_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are completely empty\n",
    "\n",
    "x = df.isnull().sum(axis=0)\n",
    "df = df.loc[:, x < len(df)]\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# Check out what other columns to drop\n",
    "x = df.isnull().sum(axis=0)\n",
    "x.hist()\n",
    "display(x[x > 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns with a lot of missing data\n",
    "df.loc[:,x>45].iloc[:, 0:11] # don't show the treatment response columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "df = df.drop(columns=['lesiongrade_type', 'exposure_description', 'rbc_2', 'hct_2', 'mcv_2', 'mchc_2', 'rdw_2', 'neutrophil_number_2', 'lymphocyte_number_2', 'monocytes_number_2', 'eosinophils_number_2', 'basophils_number_2', 'basophils_percentage_2'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    try:\n",
    "        if pd.Series(df.tbsa_diagnosis[ind]).isna()[0]:\n",
    "            continue\n",
    "        elif '%' in df.tbsa_diagnosis[ind]:\n",
    "            df.tbsa_diagnosis[ind] = df.tbsa_diagnosis[ind][:-1]\n",
    "        elif '>' in df.tbsa_diagnosis[ind]:\n",
    "            df.tbsa_diagnosis[ind] = df.tbsa_diagnosis[ind][1:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(df.tbsa_diagnosis[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tbsa_diagnosis = df.tbsa_diagnosis.apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and correct data in certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnmb_value_list = ['0', '1', '2', '3', '4', 'X']\n",
    "tnmb_list = ['t_sampling', 'n_sampling', 'm_sampling', 'b_sampling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnmb_label_list = [b +'_'+a for a in tnmb_value_list for b in tnmb_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnmb_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = df.n_sampling.apply(lambda x: math.nan if type(x) is float else tnmb_dict[x])\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert certain columns to numeric\n",
    "# df.t_sampling = df.t_sampling.apply(lambda x: math.nan if type(x) is float else tnmb_dict[x])\n",
    "# df.n_sampling = df.n_sampling.apply(lambda x: math.nan if type(x) is float else tnmb_dict[x])\n",
    "# df.m_sampling = df.m_sampling.apply(lambda x: math.nan if type(x) is float else tnmb_dict[x])\n",
    "# df.b_sampling = df.b_sampling.apply(lambda x: math.nan if type(x) is float else tnmb_dict[x])\n",
    "\n",
    "# keep t, n, m, b as catagorical variables and apply one-hot encoding\n",
    "\n",
    "for v in tnmb_value_list:\n",
    "    for tnmb in tnmb_list:\n",
    "        if df[tnmb] is not math.nan:\n",
    "            df[tnmb+'_' + v] = (df[tnmb] == v).astype(float)\n",
    "        else:\n",
    "            df[tnmb+'_' + v] = math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race: replace empty with 'Unknown'\n",
    "df.loc[pd.isnull(df.race), 'race'] = 'Unknown'\n",
    "\n",
    "# ethnicity: replace empty with 'Unknown'\n",
    "df.loc[pd.isnull(df.ethnicity), 'ethnicity'] = 'Unknown'\n",
    "\n",
    "# date of diagnosis\n",
    "# patient ID 901-4 has erroneous date\n",
    "print(df.loc['901-4', 'date_of_diagnosis'])\n",
    "df.loc['901-4', 'date_of_diagnosis'] = datetime.fromisoformat('2014-03-03')\n",
    "\n",
    "\n",
    "\n",
    "# tbsa_diagnosis\n",
    "# patient ID 900-9 has tbsa_diagnosis >80, so we changed to 80\n",
    "# patient ID 848-1 has tbsa_diagnosis 90%, so we changed to 90\n",
    "x = df.tbsa_diagnosis < 1\n",
    "df.loc[x, 'tbsa_diagnosis'] = df.tbsa_diagnosis[x] * 100\n",
    "\n",
    "# tbsa_sampling\n",
    "# patient ID 795-23 has erroneous value\n",
    "print(df.loc['795-23', 'tbsa_sampling'])\n",
    "df.loc['795-23', 'tbsa_sampling'] = np.nan\n",
    "df.tbsa_sampling = pd.to_numeric(df.tbsa_sampling, errors='coerce')\n",
    "\n",
    "# t, n, m, b columns contain values 'X' which were not part of Prof.Casey's data and thus new transformation method was developed.\n",
    "# # Convert certain columns to numeric\n",
    "# df.t_sampling = pd.to_numeric(df.t_sampling, errors='coerce', downcast='integer')\n",
    "# df.n_sampling = pd.to_numeric(df.n_sampling, errors='coerce', downcast='integer')\n",
    "# df.m_sampling = pd.to_numeric(df.m_sampling, errors='coerce', downcast='integer')\n",
    "# df.b_sampling = pd.to_numeric(df.b_sampling, errors='coerce', downcast='integer')\n",
    "\n",
    "\n",
    "# cd4cd8ratio\n",
    "# for now, replace the entered cd4:cd8 with the calculated cd4:cd8 in divergent cases\n",
    "c = df.absolute_cd4 / df.absolute_cd8\n",
    "d = (2 * np.abs(df.cd4cd8ratio - c) / (df.cd4cd8ratio + c)) > 0.2\n",
    "df.loc[d, 'cd4cd8ratio'] = c[d]\n",
    "\n",
    "# absolute_cd4_cd26\n",
    "df.loc['901-2', 'absolute_cd4_cd26'] = df.loc['901-2', 'absolute_cd4']\n",
    "\n",
    "# cbc_date\n",
    "df.loc['795-11', 'cbc_date'] = datetime.fromisoformat('2012-10-12')\n",
    "df.loc['795-36', 'cbc_date'] = datetime.fromisoformat('2014-01-15')\n",
    "df.cbc_date = pd.to_datetime(df.cbc_date, errors='coerce')\n",
    "\n",
    "# wbc\n",
    "x = df.wbc > 1000\n",
    "df.loc[x, 'wbc'] = df.loc[x, 'wbc'] / 1000\n",
    "\n",
    "# rbc\n",
    "df.loc['901-4', 'rbc'] = df.loc['901-4', 'rbc'] / 1000\n",
    "\n",
    "# hct\n",
    "# several values seem to be express percent in 0-1 range; for one person, hct in the 3.xx range, which is unreasonably low\n",
    "x = df.hct < 1\n",
    "df.loc[x, 'hct'] = df.loc[x, 'hct'] * 100\n",
    "\n",
    "# this is quite dubious, so we are leaving this out\n",
    "# x = df.hct < 10\n",
    "# df.loc[x, 'hct'] = df.loc[x, 'hct'] * 10\n",
    "\n",
    "# neutrophil number\n",
    "x = df.neutrophil_number > 1000\n",
    "df.loc[x, 'neutrophil_number'] = df.loc[x, 'neutrophil_number'] / 1000\n",
    "\n",
    "# lymphocyte number\n",
    "x = df.lymphocyte_number > 1000\n",
    "df.loc[x, 'lymphocyte_number'] = df.loc[x, 'lymphocyte_number'] / 1000\n",
    "\n",
    "# monocytes_number\n",
    "x = df.monocytes_number > 100\n",
    "df.loc[x, 'monocytes_number'] = df.loc[x, 'monocytes_number'] / 1000\n",
    "\n",
    "# eosinophils_number\n",
    "x = df.eosinophils_number > 100\n",
    "df.loc[x, 'eosinophils_number'] = df.loc[x, 'eosinophils_number'] / 1000\n",
    "\n",
    "# wbc_2\n",
    "x = df.wbc_2 > 1000\n",
    "df.loc[x, 'wbc_2'] = df.loc[x, 'wbc_2'] / 1000\n",
    "\n",
    "##### The columns below have been dropped, so no longer need to do the below cleaning steps\n",
    "\n",
    "# # rbc_2\n",
    "# x = df.rbc_2 > 100\n",
    "# df.loc[x, 'rbc_2'] = df.loc[x, 'rbc_2'] / 100\n",
    "\n",
    "# # mcv_2\n",
    "# df.loc['901-2', 'mcv_2'] = df.loc['901-2', 'mcv_2'] / 10\n",
    "\n",
    "# # neutrophil number_2\n",
    "# x = df.neutrophil_number_2 > 1000\n",
    "# df.loc[x, 'neutrophil_number_2'] = df.loc[x, 'neutrophil_number_2'] / 1000\n",
    "\n",
    "# # lymphocyte number_2\n",
    "# x = df.lymphocyte_number_2 > 1000\n",
    "# df.loc[x, 'lymphocyte_number_2'] = df.loc[x, 'lymphocyte_number_2'] / 1000\n",
    "\n",
    "# # monocytes_number_2\n",
    "# x = df.monocytes_number_2 > 100\n",
    "# df.loc[x, 'monocytes_number_2'] = df.loc[x, 'monocytes_number_2'] / 1000\n",
    "\n",
    "# # eosinophils_number_2\n",
    "# x = df.eosinophils_number_2 > 100\n",
    "# df.loc[x, 'eosinophils_number_2'] = df.loc[x, 'eosinophils_number_2'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checks after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.hist(layout=[33, 4], figsize=[20, 120])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reason: df.date_of_diagnosis['900-24'] is nan\n",
    "df = df.drop(['900-24'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_of_diagnosis['901-4'] = '2014-03-03'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age at diagnosis\n",
    "# patient ID 900-24 has date_of_diagnosis NaN. Because there is no entry for date of initial diagnosis, we dropped this patient and moved forward.\n",
    "# patient ID 901-4 has date_of_diagnosis 2014-03-03 00:00:00\n",
    "print(f'Empty DOB: {pd.isnull(df.date_of_birth).sum()}')\n",
    "print(f'Empty date of dx: {pd.isnull(df.date_of_diagnosis).sum()}')\n",
    "for ind in df.index:  \n",
    "    try:\n",
    "        df.loc[ind, 'age_at_dx'] = (datetime.strptime(df.date_of_diagnosis[ind], '%Y-%m-%d') - datetime.strptime(df.date_of_birth[ind], '%Y-%m-%d')).days/365.24\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(df.date_of_diagnosis[ind])\n",
    "        print(df.date_of_birth[ind])\n",
    "    \n",
    "df.age_at_dx.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify subtypes to MF vs SS\n",
    "display(df.subtype_variant.value_counts(dropna=False))\n",
    "\n",
    "def simplify_subtype(x):\n",
    "    if type(x) is not str:\n",
    "        return x\n",
    "    \n",
    "    return 'Mycosis fungoides' if x != 'Sezary syndrome' else x \n",
    "\n",
    "df['subtype_variant_simplified'] = df.subtype_variant.map(simplify_subtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categoricals to numeric\n",
    "# Questionable operation. Should keep them as catagorical. Fixed below when generating data at diagnosis and data at sampling\n",
    "# The survival analysis in this script only focus on the CTCL stages. Stages were kept as catagorical variables in the preprocessing steps for survival analysis.\n",
    "df['gender_n'] = df.gender.map(lambda x: int(x == 'Female') if type(x) is str else np.nan)\n",
    "df['subtype_variant_simplified_n'] = df.subtype_variant_simplified.map(lambda x: int(x == 'Sezary syndrome') if type(x) is str else np.nan)\n",
    "stage_to_numeric_dict = {\n",
    "        'IA': 1,\n",
    "        'IB': 2,\n",
    "        'IIA': 3,\n",
    "        'IIB': 4,\n",
    "        'IIIA': 5,\n",
    "        'IIIB': 6,\n",
    "        'IVA1': 7,\n",
    "        'IVA2': 8,\n",
    "        'IVB': 9\n",
    "    }\n",
    "def stage_to_numeric(x):\n",
    "    return stage_to_numeric_dict.get(x, x)\n",
    "df['stage_at_diagnosis_n'] = df.stage_at_diagnosis.map(stage_to_numeric)\n",
    "df['stage_at_sampling_n'] = df.stage_at_sampling.map(stage_to_numeric)\n",
    "\n",
    "def lesion_type_to_numeric(x):\n",
    "    map = {\n",
    "        'Patch': 1,\n",
    "        'Plaque': 2,\n",
    "        'Tumor': 3,\n",
    "        'Erythroderma': 4\n",
    "    }\n",
    "    return map.get(x, x)\n",
    "df['lesion_diagnosis_n'] = df.lesion_diagnosis.map(lesion_type_to_numeric)\n",
    "df['lesion_sampling_n'] = df.predominant_sampling.map(lesion_type_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.alive.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of survival time since dx date among patients who died\n",
    "x = ~pd.isnull(df.date_of_death)\n",
    "x2 = []\n",
    "for ind in df[x].index:\n",
    "    x2.append((datetime.strptime(df.loc[ind, 'date_of_death'], '%Y-%m-%d') - datetime.strptime(df.loc[ind, 'date_of_diagnosis'], '%Y-%m-%d')).days/365.24)\n",
    "x2 = pd.Series(x2)\n",
    "x2.hist(bins=20)\n",
    "df.loc[x, 'survival_years'] = x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment responses analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many participants had each treatment\n",
    "for i in range(1, 24):\n",
    "    c = f'prior_treatment___{i}'\n",
    "    print(f'{header_labels[c]}: {(df[c] == \"Checked\").sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get treatment names\n",
    "r = re.compile('^Treatment prior to sampling \\(choice=(.+)\\)$')\n",
    "treatment_names = [None] * 23\n",
    "for i in range(1, 24):\n",
    "    c_prior = f'prior_treatment___{i}'\n",
    "    m = r.match(header_labels[c_prior])\n",
    "    treatment_names[i-1] = m[1]\n",
    "print(treatment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if any participants are listed with the same treatment both before and after sampling\n",
    "for i in range(2, 17):\n",
    "    c_prior = f'prior_treatment___{i}'\n",
    "    c_prior_date = f'date_of_prior_treatment{i}'\n",
    "    c_prior_response = f'prior_treatment_response{i}'\n",
    "    c_prior_duration = f'duration_response_priortx{i}'\n",
    "    c_sampling = f'treatment_sampling___{i}'\n",
    "    c_after = f'after_sampling___{i}'\n",
    "    c_after_date = f'date_of_after_treatment{i}'\n",
    "    c_after_response = f'after_treatment_response{i}'\n",
    "    c_after_duration = f'duration_response_aftertx{i}'\n",
    "    \n",
    "    print(treatment_names[i-1])\n",
    "    s = ((df[c_prior] == 'Checked').astype(int) + (df[c_sampling] == 'Checked').astype(int) + (df[c_after] == 'Checked').astype(int)) > 1\n",
    "    if s.sum() > 0:\n",
    "        display(df.loc[s, [c_prior, c_prior_date, c_prior_response, c_prior_duration, c_sampling, 'date_sampling', c_after, c_after_date, c_after_response, c_after_duration]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~pd.isnull(df[c_prior_date]) & (df[c_prior_date] > df.date_sampling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if any participants have prior/after treatments with dates not matching the date regime\n",
    "for i in range(2, 17):\n",
    "    c_prior = f'prior_treatment___{i}'\n",
    "    c_prior_date = f'date_of_prior_treatment{i}'\n",
    "    c_prior_response = f'prior_treatment_response{i}'\n",
    "    c_prior_duration = f'duration_response_priortx{i}'\n",
    "    c_after = f'after_sampling___{i}'\n",
    "    c_after_date = f'date_of_after_treatment{i}'\n",
    "    c_after_response = f'after_treatment_response{i}'\n",
    "    c_after_duration = f'duration_response_aftertx{i}'\n",
    "        \n",
    "    s = ~pd.isnull(df.date_sampling) & ((~pd.isnull(df[c_prior_date]) & (df[c_prior_date] > df.date_sampling)) | (~pd.isnull(df[c_after_date]) & (df[c_after_date] < df.date_sampling)))\n",
    "    if s.sum() > 0:\n",
    "        print(treatment_names[i-1])\n",
    "        display(df.loc[s, [c_prior, c_prior_date, c_prior_response, c_prior_duration, 'date_sampling', c_after, c_after_date, c_after_response, c_after_duration]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if any participants are listed with the same treatment and date before and after sampling\n",
    "for i in range(2, 17):\n",
    "    c_prior = f'prior_treatment___{i}'\n",
    "    c_prior_date = f'date_of_prior_treatment{i}'\n",
    "    c_prior_response = f'prior_treatment_response{i}'\n",
    "    c_prior_duration = f'duration_response_priortx{i}'\n",
    "    c_after = f'after_sampling___{i}'\n",
    "    c_after_date = f'date_of_after_treatment{i}'\n",
    "    c_after_response = f'after_treatment_response{i}'\n",
    "    c_after_duration = f'duration_response_aftertx{i}'\n",
    "        \n",
    "#     s = (df[c_prior] == 'Checked') & (df[c_after] == 'Checked') & (df[c_prior_date] == df[c_after_date]) & \\\n",
    "#             (df[c_prior_duration] != df[c_after_duration]) & ~(np.isnan(df[c_prior_duration]) & np.isnan(df[c_after_duration]))\n",
    "    s = (df[c_prior] == 'Checked') & (df[c_after] == 'Checked') & (df[c_prior_duration] != df[c_after_duration]) & \\\n",
    "            ~(np.isnan(df[c_prior_duration]) & np.isnan(df[c_after_duration]))\n",
    "    if s.sum() > 0:\n",
    "        print(treatment_names[i-1])\n",
    "        display(df.loc[s, [c_prior, c_prior_date, c_prior_response, c_prior_duration, 'date_sampling', c_after, c_after_date, c_after_response, c_after_duration]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration_columns = list()\n",
    "for i in range(2, 17):                \n",
    "    max_duration_columns.append(f'max_tx_duration_response{i}')\n",
    "df[max_duration_columns] = np.nan\n",
    "\n",
    "\n",
    "# def get_max_response_durations(r):\n",
    "for index, r in df.iterrows():\n",
    "    for i in range(2, 17):\n",
    "        c_prior = f'prior_treatment___{i}'        \n",
    "        c_prior_response = f'prior_treatment_response{i}'\n",
    "        c_prior_duration = f'duration_response_priortx{i}'        \n",
    "        c_after = f'after_sampling___{i}'\n",
    "        c_after_response = f'after_treatment_response{i}'\n",
    "        c_after_duration = f'duration_response_aftertx{i}'\n",
    "        c_max_duration = f'max_tx_duration_response{i}'\n",
    "\n",
    "        durations = list()\n",
    "        if r[c_prior] == 'Checked':\n",
    "            duration = r[c_prior_duration]\n",
    "            if r[c_prior_response] == 'No':\n",
    "                durations.append(0)\n",
    "            elif r[c_prior_response] == 'Yes' and not(pd.isnull(duration)):\n",
    "                durations.append(duration)\n",
    "            # ignore cases where \"Yes\" was selected for response but no duration specified\n",
    "                \n",
    "        if r[c_after] == 'Checked':\n",
    "            duration = r[c_after_duration]\n",
    "            if r[c_after_response] == 'No':\n",
    "                durations.append(0)\n",
    "            elif r[c_after_response] == 'Yes' and not(pd.isnull(duration)):\n",
    "                durations.append(duration)\n",
    "            # ignore cases where \"Yes\" was selected for response but no duration specified\n",
    "            \n",
    "                \n",
    "        if len(durations) > 0:\n",
    "            df.loc[index, c_max_duration] = np.max(durations)\n",
    "        else:\n",
    "            df.loc[index, c_max_duration] = np.nan\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[max_duration_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_durations = [x[~pd.isnull(x)] for _, x in df[max_duration_columns].items()]\n",
    "xlabels = [treatment_names[i+1] + f' (n={len(non_nan_durations[i])})' for i in range(len(non_nan_durations))]\n",
    "\n",
    "# Sort from longest to shortest duration\n",
    "non_nan_duration_sort_values = np.array([(np.median(x), np.mean(x)) for x in non_nan_durations], dtype=[('median', np.float64), ('mean', np.float64)])\n",
    "argsort = np.flip(np.argsort(non_nan_duration_sort_values, order=('median', 'mean')))\n",
    "non_nan_durations_sorted = [non_nan_durations[i] for i in argsort]\n",
    "xlabels_sorted = [xlabels[i] for i in argsort]\n",
    "\n",
    "plt.figure(figsize=[20, 8])\n",
    "plt.boxplot(non_nan_durations_sorted, labels=xlabels_sorted)\n",
    "plt.ylabel('Response duration (months)')\n",
    "plt.xlabel('Treatment')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis test\n",
    "stats.kruskal(*non_nan_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dunn test with Holm-Sidak correction\n",
    "df_dunn = sp.posthoc_dunn(non_nan_durations_sorted, p_adjust='holm-sidak')\n",
    "df_dunn.columns = xlabels_sorted\n",
    "df_dunn.index = xlabels_sorted\n",
    "df_dunn.style.applymap(lambda x: 'color: red' if x < 0.05 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_121122.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "print(copy_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stage at diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for Cox regression\n",
    "estimated_data_entry_date = pd.Timestamp('2022-12-11')\n",
    "df[['survival', 'event']] = np.nan\n",
    "print(df.shape)\n",
    "for ind in df.index:\n",
    "    if df.alive[ind] == 'Yes':\n",
    "        df.loc[ind, 'survival'] = (estimated_data_entry_date - datetime.strptime(df.date_of_diagnosis[ind], '%Y-%m-%d')).days/365.24\n",
    "        df.loc[ind, 'event'] = 0 \n",
    "#     elif df.alive[ind] == 'No' and not pd.isnull(df.date_of_death[ind]) and not pd.isnull(df.date_of_diagnosis[ind]):\n",
    "    elif not pd.isnull(df.date_of_death[ind]) and not pd.isnull(df.date_of_diagnosis[ind]):\n",
    "        df.loc[ind, 'survival'] = (datetime.strptime(df.date_of_death[ind], '%Y-%m-%d') - datetime.strptime(df.date_of_diagnosis[ind], '%Y-%m-%d')).days/365.24\n",
    "        df.loc[ind, 'event'] = 1 \n",
    "print(df.shape)   \n",
    "df.dropna(axis=0, how='any', subset=['survival', 'event'], inplace=True)\n",
    "print(df.shape) \n",
    "df[['date_of_diagnosis', 'alive', 'date_of_death', 'survival', 'event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = [item for item in copy_df.index.to_list() if item not in df.index.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df.loc[missing, ['date_of_diagnosis', 'date_of_death', 'alive', 'redcap_data_access_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df.loc[missing, 'redcap_data_access_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_to_numeric_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many samples we have for stage_at_diagnosis\n",
    "\n",
    "# -----------------------------------\n",
    "# Bad coding... missing the ninth bar\n",
    "# df.stage_at_diagnosis_n.hist(bins=np.arange(1,10), figsize=[12,6], width=0.95)\n",
    "# plt.xticks(ticks=np.arange(1.5, 10.5, 1), labels=list(stage_to_numeric_dict.keys()))\n",
    "\n",
    "df.stage_at_diagnosis_n.hist(bins=np.arange(1,11), figsize=[12,6], width=0.95)\n",
    "plt.xticks(ticks=np.arange(1.5, 11.5, 1), labels=['IA', 'IB', 'IIA', 'IIB', 'IIIA', 'IIIB', 'IVA1', 'IVA2', 'IVB', ''])\n",
    "plt.xlabel('Stage at diagnosis')\n",
    "plt.ylabel('# Patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stage_at_diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.stage_at_diagnosis.value_counts().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of entries where stage at diagnosis is missing\n",
    "df = df[-df.stage_at_diagnosis.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all these entries have valid values under the column stage_at_sampling\n",
    "df.stage_at_sampling.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df[['survival', 'event', 'stage_at_diagnosis_n']].copy().dropna()\n",
    "# df_temp.rename(columns={'stage_at_diagnosis_n': 'stage_n'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.stage_n.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[24, 12])\n",
    "\n",
    "df_temp = df[['survival', 'event', 'stage_at_diagnosis_n']].copy().dropna()\n",
    "df_temp.rename(columns={'stage_at_diagnosis_n': 'stage_n'}, inplace=True)\n",
    "stages = list(stage_to_numeric_dict.keys())\n",
    "\n",
    "print('===========\\nstage numeric\\n===========\\n')  \n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_temp, duration_col='survival', event_col='event')\n",
    "cph.print_summary()\n",
    "# plt.subplots(figsize = (10, 6))\n",
    "# cph.plot()\n",
    "\n",
    "ax = plt.subplot(3, 4, 1)\n",
    "cph.plot_partial_effects_on_outcome(covariates='stage_n', values=np.arange(1,10), cmap='coolwarm', ax=ax)\n",
    "\n",
    "print('===========\\nstage levels\\n===========\\n')  \n",
    "def stage_levels(stage_numeric):\n",
    "    if 1 <= stage_numeric <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df_temp['stage_level'] = df_temp.stage_n.map(stage_levels)\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_temp[['survival', 'event', 'stage_level']], duration_col='survival', event_col='event')\n",
    "cph.print_summary()\n",
    "\n",
    "ax = plt.subplot(3, 4, 2)\n",
    "cph.plot_partial_effects_on_outcome(covariates='stage_level', values=np.arange(2), cmap='coolwarm', ax=ax)\n",
    "\n",
    "print('===========\\nstage levels with dummy coding\\n===========\\n')  \n",
    "df_temp['stage_levels'] = df_temp.stage_n.map(stage_levels)\n",
    "df_temp_dummy = pd.get_dummies(df_temp.stage_levels, prefix='stage')\n",
    "# df_temp['stage_early'] = df_temp_dummy['stage_0']\n",
    "df_temp['stage_late'] = df_temp_dummy['stage_1']\n",
    "# df_temp['stage_III+'] = df_temp_dummy['stage_2']\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_temp[['survival', 'event', 'stage_late']], duration_col='survival', event_col='event')\n",
    "cph.print_summary()\n",
    "\n",
    "ax = plt.subplot(3, 4, 3)\n",
    "cph.plot_partial_effects_on_outcome(covariates=['stage_late'], values=[0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "df_staged_cox = None\n",
    "\n",
    "# there is no patient at stage IVB, which is the last stage, so we remove it.\n",
    "for i in range(1, 9):\n",
    "    print(f'===========\\n{i}\\n===========\\n')\n",
    "    print(stages[i])\n",
    "    df_temp[stages[i]] = df_temp.stage_n > i\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_temp[['survival', 'event', stages[i]]], duration_col='survival', event_col='event')\n",
    "    cph.print_summary()\n",
    "\n",
    "    ax = plt.subplot(3, 4, i+3)\n",
    "    cph.plot_partial_effects_on_outcome(covariates=stages[i], values=[0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "df_temp[stages[8]] = df_temp.stage_n > 9\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep table for regularized Cox regression to be performed in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract and transform data at time of diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we should include individual malignancies\n",
    "cols_mal = [f'other_malignancies___{i}' for i in range(1, 27)]\n",
    "(df[cols_mal] == 'Checked').sum()\n",
    "\n",
    "# at most 2 cases per malignancy, so don't include the individual malignancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we should include individual expposure types\n",
    "cols = [f'exposure_type___{i}' for i in range(1, 8)]\n",
    "(df[cols] == 'Checked').sum()\n",
    "\n",
    "# at most 2 cases per exposure, except #7, which is \"other\", so donn't include individual exposure types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tcr_clone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# straight extraction of some features\n",
    "df_cox = df[['survival', 'event', 'age_at_dx', 'stage_at_diagnosis_n', 'lesion_diagnosis_n', \n",
    "             'tbsa_diagnosis', 'mswat_diagnosis', 'duration_before_dx', \n",
    "             ]].copy()\n",
    "display(df_cox.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "df_cox['gender_male'] = df.gender.map(lambda x: 1 if x == 'Male' else 0)\n",
    "\n",
    "\n",
    "# combine race/ethnicity\n",
    "# race: group other, asian, AIAN, and unknown together because few samples\n",
    "df.race.value_counts(dropna=False)\n",
    "race_replace_dict = {\n",
    "    'White': 'white',\n",
    "    'Black or African American': 'black',\n",
    "    'Asian': 'other',\n",
    "    'American Indian or Alaska Native': 'other',\n",
    "    'Other': 'other',\n",
    "    'Unknown': 'other', \n",
    "    np.nan: 'other'\n",
    "}\n",
    "race_eth_simplified = df.race.replace(race_replace_dict)\n",
    "race_eth_simplified[df.ethnicity == 'Hispanic or Latino or Spanish Origin'] = 'hispanic'\n",
    "race_eth_dummies = pd.get_dummies(race_eth_simplified, prefix='race_eth')\n",
    "df_cox = pd.concat([df_cox, race_eth_dummies[['race_eth_black', 'race_eth_other', 'race_eth_hispanic']]], axis=1)        \n",
    "\n",
    "\n",
    "# lymph node at diagnosis\n",
    "def lymph_node_diagnosis(r):\n",
    "    if pd.isnull(r.lymphnode_diagnosis) or r.lymphnode_diagnosis == 'No' :\n",
    "        return 0\n",
    "    if r.lymphnode_diagnosis == 'Yes' and not(pd.isnull(r.lymphnode_diagnosis)):\n",
    "        return int(r.lymphnode_diagnosis_2 == 'Yes')\n",
    "    \n",
    "df_cox['lymph_node_diagnosis'] = df.apply(lymph_node_diagnosis, axis=1)\n",
    "\n",
    "\n",
    "# past biopsy\n",
    "df_cox[['past_biopsy2___1',  'past_biopsy2___2', 'past_biopsy2___3', 'past_biopsy2___4', 'past_biopsy2___5']] = np.nan\n",
    "for index, r in df.iterrows():\n",
    "    if pd.isnull(r.past_biopsy) or r.past_biopsy == 'No':\n",
    "        df_cox.loc[index, ['past_biopsy2___1',  'past_biopsy2___2', 'past_biopsy2___3', 'past_biopsy2___4', 'past_biopsy2___5']] = np.nan\n",
    "    else:\n",
    "        df_cox.loc[index, ['past_biopsy2___1',  'past_biopsy2___2', 'past_biopsy2___3', 'past_biopsy2___4', 'past_biopsy2___5']] = \\\n",
    "            (df.loc[index, ['past_biopsy2___1',  'past_biopsy2___2', 'past_biopsy2___3', 'past_biopsy2___4', 'past_biopsy2___5']] == 'Checked').astype(np.int16)\n",
    "        \n",
    "        \n",
    "# history\n",
    "def simplify_yes_no_unknown(x):\n",
    "    if pd.isnull(x) or x == 'Unknown':\n",
    "        return np.nan\n",
    "    if x == 'Yes':\n",
    "        return 1\n",
    "    if x == 'No':\n",
    "        return 0    \n",
    "history_columns = ['history_ad', 'history_psoriasis', 'history_rash', 'history_pruritus', 'failed_tx', 'dupixent', 'history_autoimmune', 'history_vitd', \n",
    "                   'history_ebv', 'history_cmv', 'history_staph', 'hx_malignancy', 'fhx_leukemia', 'hazardous_exposure', ]\n",
    "df_cox[history_columns] = df[history_columns].applymap(simplify_yes_no_unknown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_to_numeric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_stage_to_numeric_dict = {v: k for k, v in stage_to_numeric_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_stage_to_numeric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert stage at diagnosis to catagorical variable and apply one-hot encoding\n",
    "\n",
    "# 91 valid records\n",
    "#df_cox.stage_at_diagnosis_n.value_counts().to_list()\n",
    "stages = ['IA', 'IB', 'IIA', 'IIB', 'IIIA', 'IIIB', 'IVA1', 'IVA2', 'IVB']\n",
    "for i in range(1, 10):\n",
    "    df_cox[stages[i-1]] = (df_cox.stage_at_diagnosis_n == i).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.loc[:, ['stage_at_diagnosis_n'] + stages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace stage_at_diagnosis_n with one-hot encoding\n",
    "df_cox = df_cox.loc[:, ~df_cox.columns.isin(['stage_at_diagnosis_n'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_diagnosis_dict = {'Patch': 1,'Plaque': 2,'Tumor': 3,'Erythroderma': 4}\n",
    "lesion = list(lesion_diagnosis_dict.keys())\n",
    "for i in range(1, 5):\n",
    "    df_cox[lesion[i-1]] = (df_cox.lesion_diagnosis_n== i).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace lesion_diagnosis_n with one-hot encoding\n",
    "df_cox = df_cox.loc[:, ~df_cox.columns.isin(['lesion_diagnosis_n'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.to_csv('cox_data_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add data from time of sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['date_sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = [item for item in copy_df_2.index.to_list() if item not in df.index.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_2.loc[missing, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some abnormal values in date of sampling that we should exclude.\n",
    "# there are 5 patients with no entry for date of sampling, so we excluded those and moved forward.\n",
    "d = []\n",
    "for ind in df.index:\n",
    "    try:\n",
    "        d.append((datetime.strptime(df.date_sampling[ind], '%Y-%m-%d') - datetime.strptime(df.date_of_diagnosis[ind], '%Y-%m-%d')).days/365.24)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(df.date_sampling[ind])\n",
    "        print(df.date_of_diagnosis[ind])\n",
    "        \n",
    "d = pd.Series(d)\n",
    "d.hist(bins=15)\n",
    "plt.xlabel('years between dx and sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# straight extraction of some features\n",
    "# df_cos only contains data at sampling\n",
    "sampling_columns = ['stage_at_sampling_n', 'lesion_sampling_n', 'tbsa_sampling', 'mswat_sampling',\n",
    "                    'cd4cd8ratio', 'absolute_cd4', 'absolute_cd8', 'ldh_sampling', 'wbc', 'hgb', 'pct', \n",
    "                    'segmented_neutrophils_percent', 'lymphocyte_percentage', 'monocytes_percentage', 'eosinophils_percentage'\n",
    "                   ] + tnmb_label_list\n",
    "df_cox[sampling_columns] = df[sampling_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.hgb['900-8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab values at time of sampling\n",
    "labs_yes_no_unk = ['tumor_cell_cd30', 'large_cell_transformation']\n",
    "df_cox[labs_yes_no_unk] = df[labs_yes_no_unk].applymap(simplify_yes_no_unknown)\n",
    "\n",
    "# patient ID 900-7 has hgb 9.2mmol, so we removed the unit\n",
    "df_cox.hgb['900-7'] = '9.2'\n",
    "\n",
    "# Treatments: just include a positive whenever any of prior/during/after sampling included\n",
    "treatment_names_sanitized = ['tx_' + re.sub('[- ]', '_', treatment_names[i]) for i in range(0, 17)]\n",
    "for i in range(2, 17):\n",
    "    c_prior = f'prior_treatment___{i}'    \n",
    "    c_sampling = f'treatment_sampling___{i}'\n",
    "    c_after = f'after_sampling___{i}'    \n",
    "    df_cox[treatment_names_sanitized[i-1]] = ((df[c_prior] == 'Checked') | (df[c_sampling] == 'Checked') | (df[c_after] == 'Checked')).astype(np.int16)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cox.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = ['IA', 'IB', 'IIA', 'IIB', 'IIIA', 'IIIB', 'IVA1', 'IVA2', 'IVB']\n",
    "for i in range(1, 10):\n",
    "    df_cox[stages[i-1] + '_at_sampling'] = (df_cox.stage_at_sampling_n == i).astype(float)\n",
    "df_cox = df_cox.loc[:, ~df_cox.columns.isin(['stage_at_sampling_n'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_sampling_dict = {'Patch': 1,'Plaque': 2,'Tumor': 3,'Erythroderma': 4}\n",
    "lesion = list(lesion_sampling_dict.keys())\n",
    "for i in range(1, 5):\n",
    "    df_cox[lesion[i-1] + '_at_sampling'] = (df_cox.lesion_sampling_n== i).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox = df_cox.loc[:, ~df_cox.columns.isin(['lesion_sampling_n'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.to_csv('cox_data_sampling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add genetic mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the common and significant mutations\n",
    "df_s6 = pd.read_excel(io=file_genetics_data, sheet_name='Table S6', header=2)\n",
    "# genes = df_s6.loc[df_s6['Number of cases with mutations'] >= 5, 'Gene Symbol'].tolist()\n",
    "genes = df_s6['Gene Symbol'].tolist()\n",
    "print(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and combine tables S2 and S3\n",
    "df_s2 = pd.read_excel(io=file_genetics_data, sheet_name='Table S2', header=2)\n",
    "x = df_s2['Gene symbol'].map(lambda x: x in genes)\n",
    "df_mutations = df_s2.loc[x, ['Gene symbol', 'Chromosome', 'Sample ID']]\n",
    "\n",
    "df_s3 = pd.read_excel(io=file_genetics_data, sheet_name='Table S3', header=2)\n",
    "x = df_s3['Gene symbol'].map(lambda x: x in genes)\n",
    "df_mutations = pd.concat([df_mutations, df_s3.loc[x, ['Gene symbol', 'Chromosome', 'Sample ID']]], axis=0)\n",
    "\n",
    "del df_s2\n",
    "del df_s3\n",
    "\n",
    "df_mutations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_mutations = pd.DataFrame(columns=genes, index=df_cox.index, data=0)\n",
    "for patient_id, sample_id in df.sample_id.items():\n",
    "    patient_genes = set(df_mutations.loc[df_mutations['Sample ID'] == sample_id, 'Gene symbol'].tolist())\n",
    "    for gene in patient_genes:\n",
    "        df_patient_mutations.loc[patient_id, gene] = 1\n",
    "    \n",
    "mut_freq = df_patient_mutations.sum()\n",
    "df_patient_mutations = df_patient_mutations.loc[:, mut_freq > 1]\n",
    "display(df_patient_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mut_freq > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list()\n",
    "for c in df_patient_mutations.columns:\n",
    "    s.append(f\"'{c}'\")\n",
    "', '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox = pd.concat([df_cox, df_patient_mutations], axis=1)\n",
    "\n",
    "# patient ID 900-7 has hgb 9.2mmol, so we removed the unit\n",
    "df_cox.hgb['900-7'] = '9.2'\n",
    "\n",
    "df_cox.to_csv('cox_data_sampling_genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox = pd.read_csv('cox_data_sampling_genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_cox.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"', '\".join(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
